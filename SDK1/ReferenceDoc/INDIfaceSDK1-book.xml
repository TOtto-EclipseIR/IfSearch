<?xml version="1.0" encoding="UTF-8"?>
<book version="5.0" xmlns="http://docbook.org/ns/docbook"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:svg="http://www.w3.org/2000/svg"
      xmlns:m="http://www.w3.org/1998/Math/MathML"
      xmlns:html="http://www.w3.org/1999/xhtml"
      xmlns:db="http://docbook.org/ns/docbook">
  <info>
    <title>INDIface SDK1 Reference</title>

    <subtitle>EclipseIR Personal Identity Recognition</subtitle>

    <author>
      <personname><firstname>Tony</firstname><surname>Otto</surname></personname>

      <affiliation>
        <jobtitle>CTO</jobtitle>

        <org>
          <orgname>Eclipse Identity Recognition Corporation</orgname>
        </org>
      </affiliation>
    </author>

    <pubdate>July 27, 2011</pubdate>

    <releaseinfo>Updated to v1.71</releaseinfo>

    <copyright>
      <year>2010-2011</year>

      <holder>Eclipse Identity Recognition Corporation. All rights reserved
      worldwide.</holder>
    </copyright>

    <legalnotice>
      <para>This document is only to be distributed under and in conformance
      with a Software Developers Agreement from Eclipse Identity Recognition
      Corporation. The agreement contains license terms to use this SDK and
      distribute binaries to your customers. By downloading, copying,
      installing or using the software you agree to this license. If you do
      not agree to this license, do not download, install, copy or use the
      software.</para>
    </legalnotice>

    <legalnotice>
      <para>ECLIPSEIR MAKES NO WARRANTY TO THE DEVELOPER AND ECLIPSEIR MAKES
      NO WARRANTY WITH RESPECT TO ANY THIRD-PARTY SOFTWARE, FIRMWARE,
      LIBRARIES, OR DATA THAT MAY BE INCORPORATED IN OR BUNDLED WITH THE SDK.
      ACCORDINGLY, ECLIPSEIR SHALL NOT BE RESPONSIBLE FOR, ANY FAILURE CAUSED
      DIRECTLY OR INDIRECTLY BY THIRD-PARTY SOFTWARE, FIRMWARE, LIBRARIES, OR
      DATA. ECLIPSEIR DOES NOT WARRANT THAT THE SDK WILL MEET DEVELOPER'S
      EXPECTATIONS OR REQUIREMENTS OR THAT USE OF THE SDK WILL BE
      UNINTERRUPTED OR ERROR-FREE.</para>
    </legalnotice>

    <legalnotice>
      <para><mediaobject>
          <imageobject>
            <imagedata fileref="../common/art/GradStack.png" scalefit="1"
                       width="2in"></imagedata>
          </imageobject>
        </mediaobject></para>
    </legalnotice>
  </info>

  <chapter>
    <title>Introduction</title>

    <mediaobject>
      <imageobject>
        <imagedata align="center" fileref="../common/art/INDIfaceH.png"
                   scalefit="1" width="6in"></imagedata>
      </imageobject>
    </mediaobject>

    <section>
      <title>Overview</title>

      <para><trademark>Eclipse Identity Recognition Corporation</trademark>
      provides <emphasis>Personal Identity Recognition</emphasis> via its
      face-based analytics known as INDIface. It is used to detect faces and
      facial features and then generate face templates for searching and
      matching. In addition, the INDIface analytics can also determine skin
      tone, upper and lower clothes color, and an estimated height of a
      person. The INDIbase system provides for the enrollment, storage,
      management, retrieval, and matching of INDIface templates. INDIbase also
      manages facial and other images as well as personal identification and
      characteristic data.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="art/SDK1-Blocks.svg" scalefit="1" width="6in"></imagedata>
        </imageobject>
      </mediaobject>

      <para>In addition to providing the base for EclipseIR's applications,
      the INDIface Software Development Kit (SDK) allows OEM developers to
      create custom applications using EclipseIR's technology. The INDIface
      SDK is currently for Windows-based stand-alone systems up to 50,000
      enrollments. In the short term, the INDIface SDK will be made available
      on most Linux- or BSD-based platforms in addition to Microsoft Windows.
      At the same time, configuration will be taken from INI files rather than
      the Windows registry. EclipseIR also plans to embed portions of its
      technologies in “Smart Cameras” pushing more capability to the edge of
      the network. EclipseIR will continue to develop more face-based
      analytics (such as demographic estimates) and other technologies for
      personal identity recognition, for example, gait recognition. As well,
      EclipseIR will pursue complementary technologies, such as the vehicular
      identity recognition. These expanded capabilities will be included in
      the SDK and/or API is appropriate to allow third-party developers to
      include them in their custom applications. At the moment the binary
      implementation of the SDK is a Windows console application
      (IfSearch.exe) and a few DLLs.</para>

      <section>
        <title>C<superscript>3</superscript></title>

        <subtitle>Configuration, Control, Command</subtitle>

        <para>The behavior of the INDIface SDK is currently controlled via the
        Windows registry. In the future we will add the ability to use INI
        and/or XML configuration files. The default is
        <filename>HKCU/Software/EclipseIR/IfSearch</filename>. Most options
        can also be specified on the command line.</para>

        <para>Most of the configuration values are "volatile," that is they
        can be changed in the registry at any time and the executing IfSearch
        will automatically pick up the changes. Things that are not volatile
        will be documented, but it is mainly in the selection of detectors and
        location of initialization files.</para>

        <para><informalfigure>
            <para><mediaobject>
                <imageobject>
                  <imagedata fileref="art/SDK1-Flow.svg" scalefit="1"
                             width="6in"></imagedata>
                </imageobject>
              </mediaobject></para>
          </informalfigure></para>
      </section>

      <section xml:id="secImageInput">
        <title>Image Input</title>

        <para>The SDK will take its input images from an IP camera or a "hot
        directory."</para>

        <section>
          <title>Live IP Input</title>

          <para>Specify the input URL with "http" as the scheme, user name and
          password if needed, host address, and a path and file name that will
          result in a single frame to be returned to IfSearch. For example
          <userinput>/Input/URL=http://demo:demo@192.168.1.90/jpg/image.jpg</userinput>.
          Most of the work so far has been with Axis 210 and 240 and a trial
          with Arecont, but any ONVIF compliant camera should work.</para>
        </section>

        <section>
          <title>Hot Directory Input</title>

          <para>Specify the input URL with "dir" as the scheme; user name,
          password, and host are ignored; the relative path starts after the
          slash following the host. To be an official URL, drive separating
          colons should be replaced with vertical stiles and Windows-style
          backslashes should be replaced with forward slashes; but we'll work
          either way. Examples:</para>

          <itemizedlist>
            <listitem>
              <para><userinput>/Input/URL=dir:///.</userinput> reads from the
              current directory</para>
            </listitem>

            <listitem>
              <para><userinput>/Input/URL=dir:////InputImages</userinput>
              reads from <filename>\InputImages</filename> on the current
              drive</para>
            </listitem>

            <listitem>
              <para><userinput>/Input/URL=dir:///T|/Input/Images/Today</userinput>
              reads from <filename>T:\Input\Images\Today</filename></para>
            </listitem>

            <listitem>
              <para><userinput>/Input/URL=dir:///T:\Input\Images\Today</userinput>
              ditto.</para>
            </listitem>
          </itemizedlist>

          <para>Hot directories have several advantages:</para>

          <itemizedlist>
            <listitem>
              <para>When all images have been processed, you can start
              processing again-mostly useful for testing or
              demonstrating.</para>
            </listitem>

            <listitem>
              <para>Images can be deleted from the directory after they have
              been processed.</para>
            </listitem>

            <listitem>
              <para>Image files can be moved to a separate directory after
              they have been processed.</para>
            </listitem>

            <listitem>
              <para>Processing can be started on an empty directory and image
              files are processed as they are dropped in to the "hot"
              directory.</para>
            </listitem>
          </itemizedlist>
        </section>
      </section>
    </section>

    <section>
      <title>Installation</title>

      <para>The SDK distribution is in a ZIP file with the default directory
      structure. Unzip it to the location of you liking.</para>

      <section>
        <title>Directory Structure</title>

        <para>This is the default directory structure. If necessary some of
        the directories can be eliminated or moved to other locations with the
        new locations specified in the registry.</para>

        <itemizedlist>
          <listitem>
            <para>./INDIface/bin-w32 contains the 32-bit Windows IfSearch
            executable and its libraries along with necessary 3rd party
            libraries.</para>
          </listitem>

          <listitem>
            <para>./INDIface/data/Face1 contains the INDIface template
            generation data files.</para>
          </listitem>

          <listitem>
            <para>./INDIface/detectors contains Detectors.XML and the actual
            detector XML data.</para>
          </listitem>

          <listitem>
            <para>./INDIface/bin-w32/imageformats contains image file format
            translators that will be used by IfSearch at start up.</para>
          </listitem>

          <listitem>
            <para>./INDIface/bin-w32/imageformats/extras contains other image
            file format translators.</para>
          </listitem>

          <listitem>
            <para>/INIDface/bin-w32/sqldrivers will contain SQL database
            interface translators in the future.</para>
          </listitem>

          <listitem>
            <para>./INDIface/FaceBase will contain person records and enrolled
            faces (normalized images and templates).</para>
          </listitem>

          <listitem>
            <para>./Sample/Input contains optional sample input data.</para>
          </listitem>

          <listitem>
            <para>./Sample/Output contains optional sample output data.</para>
          </listitem>

          <listitem>
            <para>./SampleInput/SampleFaceBase contains an optional sample
            FaceBase.</para>
          </listitem>
        </itemizedlist>

        <para>You may want to add W:\hatever\INDIface\bin to the system PATH
        so you can start IfSearch from any current directory.</para>
      </section>
    </section>
  </chapter>

  <xi:include href="BasicSteps-chap.xml" xpointer="element(/1)" />

  <chapter>
    <title>Getting Started</title>

    <para>The idea is to give you enough basic information to actually start
    working with INDIface. The information here is intentionally skeletal; you
    can find the details in the control and command reference chapter of this
    book.</para>

    <section>
      <title>First Steps</title>

      <para>The best way to learn is by doing, let's get started.</para>

      <section>
        <title>Running IfSearch for the first time</title>

        <para>Try to execute IfSearch. If we have the DLLs placed and
        registered correctly, it should start running and displaying messages
        to a DOS console window.</para>

        <programlisting>+16:55:36.205 IfSearch v1.60H built Mon Jul 12 16:05:55 2010
-16:55:36.205 INDIface Search processor Copyright (c) 2003-2010 Anthony H. Otto dba ...

+16:55:36.205 IJMcore v1.60H built Mon Jul 12 16:05:55 2010
-16:55:36.205 IJM Core Library Copyright (c) 2003-2010 Anthony H. Otto dba Dynamic ...</programlisting>

        <para>If the INDIface data files are in the expected locations, the
        detector and template generator data will be loaded.</para>

        <programlisting>-16:55:36.237 Reading detectors from D:/SVN2/trunk/IJM/release/./Detectors/Detectors.XML
+16:55:36.237 Initializing INDIface Face Detector
+16:55:36.283 Face Detector loaded: Aim8A-320 32x32
-16:55:36.283 Description: Aim8 A-series with no splits (32x32)
+16:55:36.285 Initializing INDIface Data and Parameters
-16:55:36.286 Creating INDIface data from D:/SVN2/trunk/IJM/release/Data/Face1</programlisting>

        <para>While the data files are being read, we will create the output
        directories. Since this is the first run, the output directories are
        all blank.</para>

        <programlisting>-16:55:38.203 Charcol directory set to [None]
-16:55:38.226 Detect directory set to [None]
-16:55:38.249 Skin directory set to [None]
-16:55:38.272 Enroll directory set to [None]
-16:55:38.289 Generate directory set to [None]
-16:55:38.320 BadFace directory set to [None]
-16:55:38.343 Body directory set to [None]
-16:55:38.367 Capture2 directory set to [None]
-16:55:38.390 Capture directory set to [None]
-16:55:38.413 Clothes directory set to [None]
-16:55:38.431 FaceCache directory set to [None]
-16:55:38.462 Face directory set to [None]
-16:55:38.485 Height directory set to [None]
-16:55:38.503 Image directory set to [None]
-16:55:38.534 Marked directory set to [None]
-16:55:38.557 MarkedFace directory set to [None]
-16:55:38.573 Match directory set to [None]
-16:55:38.603 NoEyes directory set to [None]
-16:55:38.626 NoFace directory set to [None]
-16:55:38.642 NoMatch directory set to [None]
-16:55:38.673 Xml directory set to [None]
-16:55:38.697 ResolveFace directory set to [None]
-16:55:38.714 ResolveMarked directory set to [None]
-16:55:38.744 Retrieve directory set to [None]
-16:55:38.767 Search directory set to [None]</programlisting>

        <para>And shortly, the INDIface initialization will be complete and
        the local FaceBase will be read. Initialization can take 15-45 seconds
        depending upon the systems capabilities and resources. Reading the
        FaceBase will, of course, depend upon the number of enrollments. In my
        example below, I had a small test enrollment and it took 200ms for 141
        faces and 73 people. However, it can take up to ten minutes to load
        50,000 enrolled faces. Since this is your first time, you will have
        zero people or faces.</para>

        <programlisting>+16:55:49.392 Initializing INDIface Template Generators
+16:55:49.392 Initializing INDIface Matcher
+16:55:49.392 Initializing INDI FaceBase
-16:55:49.392 from ../FaceBase
-16:55:49.532 INDI FaceBase Initialized: 73 People, 141 Faces, 10 Non-searchable</programlisting>

        <para>Once the FaceBase is loaded, we are ready to start processing,
        but first it logs the settings:</para>

        <programlisting>-16:55:49.532 [V       ] {Clothes/Enable} = false
-16:55:49.532 [V       ] {Detect/CharcolDir} = empty
-16:55:49.532 [V       ] {Detect/Enable} = false
-16:55:49.532 [V       ] {Detect/InputOverCrop} = 0
-16:55:49.532 [V       ] {Detect/OutputDir} = empty
-16:55:49.532 [V       ] {Detect/SkinDir} = empty
-16:55:49.532 [V       ] {Enroll/Command} = empty
-16:55:49.532 [V       ] {Enroll/OutputDir} = empty
-16:55:49.532 [V       ] {FaceColor/Enable} = false
-16:55:49.532 [V       ] {Generate/Enable} = false
-16:55:49.532 [V       ] {Generate/OutputDir} = empty
-16:55:49.532 [V       ] {Height/Enable} = false
-16:55:49.532 [V       ] {Input/Pause} = false
-16:55:49.532 [V       ] {Input/URL} = empty
-16:55:49.532 [V       ] {Match/Enable} = false
-16:55:49.532 [        ] {Options/NoPrompt} = true
-16:55:49.532 [V       ] {Options/Shutdown} = false
-16:55:49.532 [V       ] {Output/BadFaceDir} = empty
-16:55:49.532 [V       ] {Output/BaseDir} = ../Output
-16:55:49.532 [V       ] {Output/BodyDir} = empty
-16:55:49.532 [V       ] {Output/Capture2Dir} = empty
-16:55:49.532 [V       ] {Output/CaptureDir} = empty
-16:55:49.548 [V       ] {Output/ClothesDir} = empty
-16:55:49.548 [V       ] {Output/FaceCacheDir} = empty
-16:55:49.548 [V       ] {Output/FaceDir} = empty
-16:55:49.548 [V       ] {Output/FaceFormat} = PNG
-16:55:49.548 [V       ] {Output/FaceQuality} = -1
-16:55:49.548 [V       ] {Output/ForceMarked} = false
-16:55:49.548 [V       ] {Output/Format} = JPG
-16:55:49.548 [V       ] {Output/HeightDir} = empty
-16:55:49.548 [V       ] {Output/ImageDir} = empty
-16:55:49.548 [        ] {Output/LogDetail} = Info
-16:55:49.563 [        ] {Output/LogFile} = ../Output/log/@.log
-16:55:49.563 [V       ] {Output/MarkAllColor} = #000000
-16:55:49.563 [V       ] {Output/MarkBackgroundColor} = #000000
-16:55:49.563 [V       ] {Output/MarkBackgroundFile} = empty
-16:55:49.563 [V       ] {Output/MarkBackgroundTransparency} = 100
-16:55:49.563 [V       ] {Output/MarkBadFaceColor} = #00ff00
-16:55:49.563 [V       ] {Output/MarkClothes} = false
-16:55:49.563 [V       ] {Output/MarkedDir} = empty
-16:55:49.563 [V       ] {Output/MarkedFaceDir} = empty
-16:55:49.563 [V       ] {Output/MarkEyeColor} = #ffff00
-16:55:49.579 [V       ] {Output/MarkEyeRoiColor} = #000000
-16:55:49.579 [V       ] {Output/MarkFaceColor} = #ffff00
-16:55:49.579 [V       ] {Output/MarkNoEyesColor} = #0000ff
-16:55:49.579 [V       ] {Output/MarkOverCrop} = 133
-16:55:49.579 [V       ] {Output/MatchDir} = empty
-16:55:49.579 [V       ] {Output/MaxCache} = 64
-16:55:49.579 [V       ] {Output/NoEyesDir} = empty
-16:55:49.579 [V       ] {Output/NoFaceDir} = empty
-16:55:49.579 [V       ] {Output/NoMatchDir} = empty
-16:55:49.579 [V       ] {Output/Quality} = -1
-16:55:49.579 [V       ] {Output/WriteFaceInfo} = true
-16:55:49.579 [V       ] {Output/XmlDir} = empty
-16:55:49.579 [V       ] {Resolve/Consistency} = 0
-16:55:49.579 [V       ] {Resolve/Enable} = false
-16:55:49.579 [V       ] {Resolve/FaceColor} = 0
-16:55:49.579 [V       ] {Resolve/FaceDir} = empty
-16:55:49.579 [V       ] {Resolve/Height} = 0
-16:55:49.579 [V       ] {Resolve/LowerClothes} = 0
-16:55:49.579 [V       ] {Resolve/MarkedDir} = empty
-16:55:49.579 [V       ] {Resolve/MaxConfidence} = 0
-16:55:49.595 [V       ] {Resolve/MinConfidence} = 0
-16:55:49.595 [V       ] {Resolve/Quality} = 0
-16:55:49.595 [V       ] {Resolve/UpperClothes} = 0
-16:55:49.595 [V       ] {Retrieve/Command} = empty
-16:55:49.595 [V       ] {Retrieve/OutputDir} = empty
-16:55:49.595 [V       ] {Search/Command} = empty
-16:55:49.595 [V       ] {Search/OutputDir} = empty</programlisting>

        <para>And properties:</para>

        <programlisting>-16:55:49.595 [V       ] {Clothes/Ankle} for 943408 = 0
-16:55:49.595 [V       ] {Clothes/LowerColor} for 943408 = empty
-16:55:49.595 [V       ] {Clothes/LowerConfidence} for 943408 = 0
-16:55:49.610 [V       ] {Clothes/Shoulder} for 943408 = 0
-16:55:49.610 [V       ] {Clothes/UnderCrop} for 943408 = 0
-16:55:49.610 [V       ] {Clothes/UpperColor} for 943408 = empty
-16:55:49.610 [V       ] {Clothes/UpperConfidence} for 943408 = 0
-16:55:49.610 [V       ] {Clothes/Waist} for 943408 = 0
-16:55:49.610 [V       ] {Clothes/Width} for 943408 = 0
-16:55:49.610 [V       ] {Detect/Factor} for 95a520 = 0
-16:55:49.610 [V       ] {Detect/MaxAcross} for 95a520 = 0
-16:55:49.610 [V       ] {Detect/MaxPixels} for 95a520 = 0
-16:55:49.610 [V       ] {Detect/MaxResults} for 95a520 = 0
-16:55:49.626 [V       ] {Detect/MinAcross} for 95a520 = 0
-16:55:49.626 [V       ] {Detect/MinPixels} for 95a520 = 0
-16:55:49.626 [V       ] {Detect/MinQuality} for 95a520 = 0
-16:55:49.626 [V       ] {Generate/EyeScale} for 94f230 = 0
-16:55:49.626 [        ] {Generate/LeftDetector} for 94f230 = empty
-16:55:49.626 [V       ] {Generate/MinConsistency} for 94f230 = 0
-16:55:49.626 [        ] {Generate/RightDetector} for 94f230 = empty
-16:55:49.626 [V       ] {Generate/RoiScale} for 94f230 = 0
-16:55:49.626 [V       ] {Height/GridCols} for 94fc88 = 0
-16:55:49.626 [V       ] {Height/GridFile} for 94fc88 = empty
-16:55:49.626 [V       ] {Height/GridRows} for 94fc88 = 0
-16:55:49.626 [V       ] {Height/HeightScale} for 94fc88 = 0
-16:55:49.626 [V       ] {Height/MinConfidence} for 94fc88 = 0
-16:55:49.626 [V       ] {Height/MinConsistency} for 94fc88 = 0
-16:55:49.626 [V       ] {Height/TargetEyePixels} for 94fc88 = 0
-16:55:49.626 [V       ] {Height/TargetHeight} for 94fc88 = 0
-16:55:49.626 [V       ] {Input/DeleteAfter} for a4ebd0 = false
-16:55:49.626 [V A     ] {Input/Loop} for a4ebd0 = false
-16:55:49.626 [V A     ] {Input/MaxCache} for a4ebd0 = 0
-16:55:49.626 [V A     ] {Input/MaxCache} for 946230 = 0
-16:55:49.641 [V       ] {Input/MoveAfter} for a4ebd0 = empty
-16:55:49.641 [V A     ] {Input/NewestOnly} for a4ebd0 = false
-16:55:49.641 [V       ] {Input/NewOnly} for a4ebd0 = false
-16:55:49.641 [V       ] {Input/SampleMsec} for a4ebd0 = 0
-16:55:49.641 [V       ] {Input/SampleMsec} for 946230 = 0
-16:55:49.641 [V       ] {Match/DuplicateThreshold} for 28fd58 = 6
-16:55:49.641 [V       ] {Match/MaxDistance} for 28fd58 = 0
-16:55:49.641 [V       ] {Match/MaxFaces} for 28fd58 = 0
-16:55:49.641 [V       ] {Match/MaxPersonFaces} for 28fd58 = 5
-16:55:49.641 [V       ] {Match/MaxResults} for 28fd58 = 0
-16:55:49.657 [V       ] {Match/MinConfidence} for 28fd58 = 0
-16:55:49.657 [V       ] {Match/MinDistance} for 28fd58 = 0
-16:55:49.657 [V       ] {Match/PersonMethod} for 28fd58 = 0
-16:55:49.657 [V       ] {Match/PersonMode} for 28fd58 = true
-16:55:49.657 [V       ] {Options/UpdateMsec} for 948c68 = 0
-16:55:49.657 [V       ] {Search/DuplicateThreshold} for 28fd90 = 6
-16:55:49.657 [V       ] {Search/MaxDistance} for 28fd90 = 0
-16:55:49.657 [V       ] {Search/MaxFaces} for 28fd90 = 0
-16:55:49.657 [V       ] {Search/MaxPersonFaces} for 28fd90 = 5
-16:55:49.657 [V       ] {Search/MaxResults} for 28fd90 = 0
-16:55:49.673 [V       ] {Search/MinConfidence} for 28fd90 = 0
-16:55:49.673 [V       ] {Search/MinDistance} for 28fd90 = 0
-16:55:49.673 [V       ] {Search/PersonMethod} for 28fd90 = 0
-16:55:49.673 [V       ] {Search/PersonMode} for 28fd90 = true</programlisting>

        <para>IfSearch is ready to rock and roll, but since we haven't set any
        controls in the registry, it is pretty well emulating a brick
        now.</para>
      </section>

      <section>
        <title>The Log File</title>

        <para>The log is an important place to start to learn about IfSearch
        and to request assistance. By default the log is written to
        <userinput>../Output/log/@.log</userinput> relative to where IfSearch
        was started. If you started IfSearch from its bin directory, then look
        for the log file at
        <filename>W:\hatever\INDIface\Output\log\D20100710-T1655.log</filename>.
        Note that the at-sign in the file name specification is replaced by
        the date and time that IfSearch is started. If you would like to move
        the log file elsewhere, specify LogFile in the Output key of the
        registry, for example:
        <userinput>/Output/LogFile=../Output/@/IfSearch.log</userinput>. The
        detail level of the log file defaults to "Info," as does the output to
        the console window. Sometimes for debugging purposes it is useful to
        set the detail level to something else by setting the LogDetail value
        in the Output key, for example
        <userinput>/Output/LogDetail=Detail</userinput>. Output/LogFile and
        Output/LogDetail are not, however, volatile registry entries; if you
        change those values, you need to start IfSearch again.</para>

        <para>You will note that it isn't happy because we haven't given it
        any configuration, such as where to get its input.</para>

        <programlisting>-16:10:25.165 Input/URL changed to %2
&gt;16:10:25.165 IfSearchSlots 139 Input/URL is empty
-16:10:25.165 Input/Pause changed to false
+16:10:25.166 ---RESUME---
&gt;16:10:25.166 IfSearchSlots 82  Nothing for InputHotdir::cacheFirst()</programlisting>
      </section>

      <section>
        <title>Making the Registry Volatile</title>

        <para>It is handy to be able to change most configuration values on
        the fly. To have IfSearch recognize the changes, the registry needs to
        be "volatile." Set the UpdateMsec value in the Options key to a
        non-zero number of milliseconds of how often to scan the registry for
        changed values. For example:
        <userinput>/Options/UpdateMsec=1000</userinput> will check for changes
        ever second; good values range from 500 to 5000.</para>

        <para>It may take several seconds for it to acknowledge the change to
        UpdateMsec, but after that it will scan as often as you
        specified.</para>

        <programlisting>-16:11:25.186 Options/UpdateMsec changed to 1000</programlisting>
      </section>

      <section>
        <title>Getting Input</title>

        <para>Now that the registry is volatile, we can change values and have
        IfSearch respond the next time the registry is scanned. Let's tell it
        where to get input images. We can add an Input key to the registry
        then add a string value for URL and set the contents. For example,
        <userinput>/Input/URL=http://demo:demo@192.168.85.90/jpg/image.jpg</userinput>
        will start it grabbing images from an Axis camera.</para>

        <programlisting>-16:12:04.726 Input/URL changed to http://demo:demo@192.168.85.90/jpg/image.jpg
+16:12:09.231 http://demo:demo@192.168.85.90/jpg/image.jpg Started
+16:12:10.487 ===Processing D20100714-T161210477
-16:12:10.487 ^^^No faces in D20100714-T161210477
+16:12:11.338 ===Processing D20100714-T161211327
-16:12:11.338 ^^^No faces in D20100714-T161211327
+16:12:12.358 ===Processing D20100714-T161212348
-16:12:12.359 ^^^No faces in D20100714-T161212348
+16:12:13.399 ===Processing D20100714-T161213388
-16:12:13.399 ^^^No faces in D20100714-T161213388
+16:12:14.381 ===Processing D20100714-T161214371
-16:12:14.381 ^^^No faces in D20100714-T161214371
+16:12:15.411 ===Processing D20100714-T161215401
-16:12:15.411 ^^^No faces in D20100714-T161215401
+16:12:16.439 ===Processing D20100714-T161216429
-16:12:16.439 ^^^No faces in D20100714-T161216429
+16:12:17.429 ===Processing D20100714-T161217419
-16:12:17.429 ^^^No faces in D20100714-T161217419
+16:12:18.474 ===Processing D20100714-T161218464
-16:12:18.474 ^^^No faces in D20100714-T161218464</programlisting>

        <para>Sometimes it is handy to be able to pause image input to analyze
        what is happening. Setting <userinput>/Input/Pause=true</userinput>
        will do this.</para>

        <programlisting>-16:12:18.922 Input/Pause changed to 1</programlisting>

        <para><warning xml:id="warnInputPause">
            <para>Setting <userinput>/Input/Pause=true</userinput> will do
            this. But don't forget to un-pause later (/Input/Pause=false),
            especially if you restart IfSearch with it paused in the registry.
            I can't count the times I've had the following conversation:
            "Tony, it's completely broken, I'm getting zero output." "Is it
            paused?" "Oh, never mind."</para>
          </warning></para>

        <para></para>
      </section>

      <section>
        <title>Writing Output</title>

        <para>Now that we have input, lets do something with our results. The
        base output directory defaults to ../Output; I like to change it
        slightly while learning and debugging and you can relocate it to a
        temporary area if you like. Set
        <userinput>Output/BaseDir=../Output/@</userinput> or
        <userinput>Output/BaseDir=T:/Temp/INDIout/@</userinput>. Once again
        the at-sign is converted to a date/time stamp, this time for the
        subdirectory name. This allows you to have the results of recent runs
        separated and you can delete early unproductive runs. Also, you might
        want to change <userinput>/Output/LogFile=./IfSearch.log</userinput>
        to keep the log file with the output directories.</para>

        <para><warning>
            <para>Remember that changes to <varname>LogFile</varname> and
            <varname>LogDetail</varname> do not take effect until IfSearch is
            started again.</para>
          </warning> And lets capture our input frames by setting
        <userinput>/Output/CaptureDir=Capture</userinput>.</para>

        <programlisting>-17:20:25.189 Output/BaseDir changed to ../Output/@
-17:20:25.314 AvgFace directory set to [None]
-17:20:25.314 Charcol directory set to [None]
-17:20:25.314 Detect directory set to [None]
-17:20:25.314 Skin directory set to [None]
-17:20:25.314 Enroll directory set to [None]
-17:20:25.314 Generate directory set to [None]
-17:20:25.314 BadFace directory set to [None]
-17:20:25.314 Body directory set to [None]
-17:20:25.314 Capture2 directory set to [None]
-17:20:25.314 Capture directory set to [None]
-17:20:25.314 Clothes directory set to [None]
-17:20:25.314 FaceCache directory set to [None]
-17:20:25.314 Face directory set to [None]
-17:20:25.314 Height directory set to [None]
-17:20:25.314 Image directory set to [None]
-17:20:25.314 Marked directory set to [None]
-17:20:25.314 MarkedFace directory set to [None]
-17:20:25.314 Match directory set to [None]
-17:20:25.314 NoEyes directory set to [None]
-17:20:25.314 NoFace directory set to [None]
-17:20:25.314 NoMatch directory set to [None]
-17:20:25.314 Xml directory set to [None]
-17:20:25.314 ResolveFace directory set to [None]
-17:20:25.314 ResolveMarked directory set to [None]
-17:20:25.314 Retrieve directory set to [None]
-17:20:25.314 Search directory set to [None]
-17:20:31.273 Output/CaptureDir changed to Capture
-17:20:31.476 Capture directory set to D:/SVN2/trunk/IJM/Output/D20100715-T1719/Capture
-17:20:41.416 Input/Pause changed to 0
+17:20:41.416 ---RESUME---
&gt;17:20:41.416 IfSearchSlots 82  Nothing for InputHotdir::cacheFirst()
+17:20:42.182 ===Processing D20100715-T172042166
-17:20:42.182 ^^^No faces in D20100715-T172042166
+17:20:43.012 ===Processing D20100715-T172042996
-17:20:43.012 ^^^No faces in D20100715-T172042996
+17:20:44.044 ===Processing D20100715-T172044029
-17:20:44.044 ^^^No faces in D20100715-T172044029
+17:20:45.061 ===Processing D20100715-T172045046
-17:20:45.061 ^^^No faces in D20100715-T172045046
+17:20:46.063 ===Processing D20100715-T172046047
-17:20:46.063 ^^^No faces in D20100715-T172046047
+17:20:47.080 ===Processing D20100715-T172047064
-17:20:47.080 ^^^No faces in D20100715-T172047064
+17:20:48.112 ===Processing D20100715-T172048097
-17:20:48.112 ^^^No faces in D20100715-T172048097
+17:20:49.098 ===Processing D20100715-T172049082
-17:20:49.098 ^^^No faces in D20100715-T172049082
+17:20:50.162 ===Processing D20100715-T172050146
-17:20:50.162 ^^^No faces in D20100715-T172050146
+17:20:51.161 ===Processing D20100715-T172051146
-17:20:51.161 ^^^No faces in D20100715-T172051146
-17:20:51.554 Input/Pause changed to 1</programlisting>

        <informalfigure>
          <para>What did we get? Looking at ../Output/Capture, you got images
          like these two:</para>
        </informalfigure>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/D20100715-T172045046.jpg"></imagedata>
          </imageobject>
        </mediaobject>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/D20100715-T172046047.jpg"></imagedata>
          </imageobject>
        </mediaobject>

        <para>So we now have a poor-man's MJPEG capture facility to capture
        live video from an IP camera to a directory of JPG files. If you were
        using a hot directory for input, you've just invented the copy
        command.</para>
      </section>
    </section>

    <section xml:id="chapGettingStarted">
      <title>Finding Faces</title>

      <para></para>

      <section>
        <title>Detecting Possible Faces</title>

        <para>The first step in the INDIface process is detection of potential
        frontal faces in the capture image. We will enable it, but without any
        other parameters it will accept almost anything as a potential face:
        Any size, any quality, and any number per frame. Set
        <userinput>/Output/FaceDir=Face</userinput>, then create a new
        IfSearch registry key for Detect if necessary, and set
        <userinput>/Detect/Enable=true</userinput>. Now we're detecting
        potential faces.</para>

        <programlisting>-17:28:25.833 Output/FaceDir changed to Face
-17:27:31.078 Detect/Enable changed to true
-17:28:25.958 Face directory set to D:/SVN2/trunk/IJM/Output/D20100715-T1719/Face
-17:28:36.987 Input/Pause changed to false
+17:28:36.987 ---RESUME---
&gt;17:28:36.987 IfSearchSlots 82  Nothing for InputHotdir::cacheFirst()
+17:28:37.737 ===Processing	 D20100715-T172837722
+17:28:37.957 ---75-pixel face at 414, 332 Q94
-17:28:37.957    Good Consistency 0
-17:28:37.989 ^^^Processing complete: D20100715-T172837722
+17:28:38.587 ===Processing	 D20100715-T172838571
+17:28:39.009 ---130-pixel face at 333, 144 Q985
-17:28:39.009    Good Consistency 0
+17:28:39.148 ---232-pixel face at 451, 202 Q510
-17:28:39.148    Good Consistency 0
+17:28:39.560 ---70-pixel face at 643, 441 Q391
-17:28:39.560    Good Consistency 0
+17:28:39.590 ---78-pixel face at 488, 435 Q354
-17:28:39.590    Good Consistency 0
+17:28:39.631 ---66-pixel face at 216, 134 Q342
-17:28:39.631    Good Consistency 0
+17:28:39.666 ---69-pixel face at 647, 225 Q314
-17:28:39.666    Good Consistency 0
+17:28:39.701 ---154-pixel face at 151, 281 Q300
-17:28:39.701    Good Consistency 0
+17:28:39.895 ---57-pixel face at 244, 72 Q284
-17:28:39.895    Good Consistency 0
+17:28:39.921 ---86-pixel face at 636, 296 Q250
-17:28:39.921    Good Consistency 0
+17:28:39.967 ---89-pixel face at 44, 436 Q212
-17:28:39.967    Good Consistency 0
+17:28:40.009 ---66-pixel face at 322, 332 Q189
-17:28:40.009    Good Consistency 0
+17:28:40.041 ---37-pixel face at 580, 458 Q189
-17:28:40.041    Good Consistency 0
+17:28:40.056 ---134-pixel face at 551, 200 Q164
-17:28:40.056    Good Consistency 0
+17:28:40.223 ---62-pixel face at 500, 404 Q164
-17:28:40.223    Good Consistency 0
+17:28:40.257 ---75-pixel face at 402, 96 Q134
-17:28:40.257    Good Consistency 0
+17:28:40.306 ---69-pixel face at 163, 130 Q134
-17:28:40.306    Good Consistency 0
+17:28:40.345 ---62-pixel face at 82, 84 Q134
-17:28:40.345    Good Consistency 0
+17:28:40.377 ---63-pixel face at 631, 199 Q134
-17:28:40.377    Good Consistency 0
+17:28:40.409 ---59-pixel face at 631, 355 Q134
-17:28:40.409    Good Consistency 0
+17:28:40.432 ---52-pixel face at 661, 355 Q134
-17:28:40.432    Good Consistency 0
+17:28:40.451 ---47-pixel face at 151, 185 Q134
-17:28:40.451    Good Consistency 0
+17:28:40.469 ---35-pixel face at 343, 421 Q134
-17:28:40.469    Good Consistency 0
+17:28:40.501 ---122-pixel face at 208, 383 Q94
-17:28:40.501    Good Consistency 0
+17:28:40.609 ---57-pixel face at 166, 218 Q94
-17:28:40.609    Good Consistency 0
+17:28:40.637 ---57-pixel face at 442, 446 Q94
-17:28:40.637    Good Consistency 0
+17:28:40.658 ---52-pixel face at 575, 299 Q94
-17:28:40.658    Good Consistency 0
+17:28:40.676 ---43-pixel face at 21, 207 Q94
-17:28:40.676    Good Consistency 0
+17:28:40.688 ---39-pixel face at 347, 29 Q94
-17:28:40.688    Good Consistency 0
+17:28:40.698 ---39-pixel face at 521, 31 Q94
-17:28:40.698    Good Consistency 0
+17:28:40.709 ---39-pixel face at 235, 67 Q94
-17:28:40.709    Good Consistency 0
+17:28:40.722 ---39-pixel face at 79, 307 Q94
-17:28:40.722    Good Consistency 0
+17:28:40.734 ---35-pixel face at 543, 63 Q94
-17:28:40.734    Good Consistency 0
+17:28:40.832 ---35-pixel face at 651, 101 Q94
-17:28:40.833    Good Consistency 0
+17:28:40.842 ---32-pixel face at 107, 99 Q94
-17:28:40.842    Good Consistency 0
+17:28:40.850 ---32-pixel face at 485, 327 Q94
-17:28:40.850    Good Consistency 0
+17:28:40.858 ---32-pixel face at 429, 341 Q94
-17:28:40.858    Good Consistency 0
+17:28:40.866 ---32-pixel face at 315, 363 Q94
-17:28:40.866    Good Consistency 0
-17:28:40.875 ^^^Processing complete: D20100715-T172838571
+17:28:40.888 ===Processing	 D20100715-T172840501
+17:28:41.321 ---277-pixel face at 421, 228 Q999
-17:28:41.321    Good Consistency 0
+17:28:41.908 ---261-pixel face at 214, 270 Q379
-17:28:41.908    Good Consistency 0
+17:28:42.404 ---88-pixel face at 404, 413 Q284
-17:28:42.404    Good Consistency 0
+17:28:42.462 ---196-pixel face at 482, 305 Q268
-17:28:42.462    Good Consistency 0
+17:28:42.749 ---72-pixel face at 644, 442 Q268
-17:28:42.749    Good Consistency 0
+17:28:42.781 ---66-pixel face at 216, 136 Q268
-17:28:42.781    Good Consistency 0
+17:28:42.839 ---67-pixel face at 641, 233 Q268
-17:28:42.839    Good Consistency 0
+17:28:42.871 ---85-pixel face at 639, 299 Q232
-17:28:42.872    Good Consistency 0
+17:28:42.918 ---122-pixel face at 345, 159 Q212
-17:28:42.918    Good Consistency 0
+17:28:43.040 ---62-pixel face at 84, 82 Q212
-17:28:43.040    Good Consistency 0
+17:28:43.070 ---59-pixel face at 633, 353 Q212
-17:28:43.070    Good Consistency 0
+17:28:43.129 ---40-pixel face at 237, 69 Q212
-17:28:43.129    Good Consistency 0
+17:28:43.144 ---59-pixel face at 581, 449 Q189
-17:28:43.144    Good Consistency 0
+17:28:43.170 ---57-pixel face at 162, 132 Q134
-17:28:43.170    Good Consistency 0
+17:28:43.198 ---54-pixel face at 664, 356 Q134
-17:28:43.198    Good Consistency 0
+17:28:43.217 ---83-pixel face at 51, 435 Q94
-17:28:43.217    Good Consistency 0
+17:28:43.256 ---62-pixel face at 440, 426 Q94
-17:28:43.257    Good Consistency 0
+17:28:43.286 ---57-pixel face at 636, 200 Q94
-17:28:43.286    Good Consistency 0
+17:28:43.311 ---52-pixel face at 145, 87 Q94
-17:28:43.311    Good Consistency 0
+17:28:43.332 ---52-pixel face at 29, 317 Q94
-17:28:43.332    Good Consistency 0
+17:28:43.372 ---52-pixel face at 247, 389 Q94
-17:28:43.373    Good Consistency 0
+17:28:43.393 ---39-pixel face at 519, 33 Q94
-17:28:43.393    Good Consistency 0
+17:28:43.404 ---35-pixel face at 423, 455 Q94
-17:28:43.404    Good Consistency 0
+17:28:43.413 ---32-pixel face at 103, 25 Q94
-17:28:43.413    Good Consistency 0
+17:28:43.421 ---32-pixel face at 227, 39 Q94
-17:28:43.421    Good Consistency 0
+17:28:43.429 ---32-pixel face at 649, 103 Q94
-17:28:43.430    Good Consistency 0
+17:28:43.438 ---32-pixel face at 471, 431 Q94
-17:28:43.438    Good Consistency 0
-17:28:43.446 ^^^Processing complete: D20100715-T172840501</programlisting>

        <para>You see that the log reports each possible face noting the width
        (in pixels) of the detected face, the x- and y-coordinates of the
        center, and a "Quality" of face detection, ranging here from 999 down
        to 94.</para>

        <informalfigure>
          <para>What did we get in the Face directory? There are a few good
          faces in there, probably the ones with the 999 quality; but there
          are some that really only look like a face to a computer.</para>
        </informalfigure>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Sheet_002.jpg"></imagedata>
          </imageobject>
        </mediaobject>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Sheet_001.jpg"></imagedata>
          </imageobject>
        </mediaobject>
      </section>

      <section>
        <title>Better Faces</title>

        <para>Let's only look at fairly good quality possible face detections.
        Set <userinput>/Detect/MinQuality=400</userinput> and maybe
        <userinput>/Detect/MaxResults=5</userinput> to limit the bad
        faces.</para>

        <programlisting>-18:20:02.771 Input/URL changed to http://demo:demo@192.168.85.90/jpg/image.jpg
+18:20:07.624 http://demo:demo@192.168.85.90/jpg/image.jpg Started
-18:20:07.624 Input/Pause changed to 1
-18:20:07.624 Options/Shutdown changed to false
-18:21:49.234 Detect/MinQuality changed to 
-18:21:50.248 Detect/MinQuality changed to 0
-18:21:51.262 Detect/MinQuality changed to 400
-18:21:59.374 Detect/MaxResults changed to 
-18:22:00.388 Detect/MaxResults changed to 0
-18:22:01.402 Detect/MaxResults changed to 
-18:22:02.416 Detect/MaxResults changed to 0
-18:22:03.430 Detect/MaxResults changed to 5
-18:22:20.668 Input/Pause changed to 0
+18:22:20.668 ---RESUME---
&gt;18:23:53.948 IfSearchSlots 82  Nothing for InputHotdir::cacheFirst()
+18:23:55.010 ===Processing	 D20100715-T182354995
+18:23:55.370 ---169-pixel face at 348, 167 Q994
-18:23:55.370    Good Consistency 0
-18:23:55.531 ^^^Processing complete: D20100715-T182354995
+18:23:55.858 ===Processing	 D20100715-T182355842
+18:23:56.233 ---155-pixel face at 353, 214 Q999
-18:23:56.233    Good Consistency 0
-18:23:56.396 ^^^Processing complete: D20100715-T182355842
+18:23:56.878 ===Processing	 D20100715-T182356862
+18:23:57.331 ---151-pixel face at 348, 198 Q999
-18:23:57.331    Good Consistency 0
-18:23:57.506 ^^^Processing complete: D20100715-T182356862
+18:23:57.911 ===Processing	 D20100715-T182357895
+18:23:58.426 ---179-pixel face at 323, 225 Q999
-18:23:58.426    Good Consistency 0
-18:23:58.714 ^^^Processing complete: D20100715-T182357895
+18:23:58.895 ===Processing	 D20100715-T182358879
+18:23:59.442 ---194-pixel face at 362, 202 Q999
-18:23:59.442    Good Consistency 0
-18:23:59.746 ^^^Processing complete: D20100715-T182358879
+18:23:59.927 ===Processing	 D20100715-T182359911
+18:24:00.427 ---164-pixel face at 363, 195 Q884
-18:24:00.427    Good Consistency 0
-18:24:00.646 ^^^Processing complete: D20100715-T182359911
+18:24:00.953 ===Processing	 D20100715-T182400938
+18:24:01.422 ---181-pixel face at 360, 176 Q782
-18:24:01.422    Good Consistency 0
+18:24:01.657 ---70-pixel face at 210, 96 Q434
-18:24:01.657    Good Consistency 0
-18:24:01.698 ^^^Processing complete: D20100715-T182400938
+18:24:01.936 ===Processing	 D20100715-T182401920
+18:24:02.311 ---156-pixel face at 353, 206 Q999
-18:24:02.311    Good Consistency 0
+18:24:02.482 ---76-pixel face at 169, 103 Q444
-18:24:02.483    Good Consistency 0
-18:24:02.523 ^^^Processing complete: D20100715-T182401920
+18:24:02.984 ===Processing	 D20100715-T182402969
+18:24:03.469 ---158-pixel face at 348, 204 Q999
-18:24:03.469    Good Consistency 0
+18:24:03.679 ---93-pixel face at 608, 184 Q454
-18:24:03.679    Good Consistency 0
-18:24:03.765 ^^^Processing complete: D20100715-T182402969
+18:24:04.017 ===Processing	 D20100715-T182404002
+18:24:04.440 ---156-pixel face at 353, 211 Q999
-18:24:04.440    Good Consistency 0
+18:24:04.628 ---91-pixel face at 641, 243 Q483
-18:24:04.628    Good Consistency 0
-18:24:04.693 ^^^Processing complete: D20100715-T182404002
+18:24:04.978 ===Processing	 D20100715-T182404962
+18:24:05.447 ---183-pixel face at 367, 177 Q999
-18:24:05.447    Good Consistency 0
-18:24:05.664 ^^^Processing complete: D20100715-T182404962
+18:24:06.010 ===Processing	 D20100715-T182405995
+18:24:06.401 ---173-pixel face at 367, 199 Q999
-18:24:06.401    Good Consistency 0
-18:24:06.624 ^^^Processing complete: D20100715-T182405995
+18:24:07.021 ===Processing	 D20100715-T182407006
-18:24:07.272 ^^^No faces in D20100715-T182407006
+18:24:08.023 ===Processing	 D20100715-T182408007
-18:24:08.273 ^^^No faces in D20100715-T182408007
+18:24:09.071 ===Processing	 D20100715-T182409055
-18:24:09.321 ^^^No faces in D20100715-T182409055
+18:24:10.088 ===Processing	 D20100715-T182410072
-18:24:10.338 ^^^No faces in D20100715-T182410072
+18:24:11.058 ===Processing	 D20100715-T182411042
-18:24:11.309 ^^^No faces in D20100715-T182411042
+18:24:12.107 ===Processing	 D20100715-T182412092
-18:24:12.358 ^^^No faces in D20100715-T182412092
+18:24:13.124 ===Processing	 D20100715-T182413093
-18:24:13.359 ^^^No faces in D20100715-T182413093
+18:24:14.110 ===Processing	 D20100715-T182414094
-18:24:14.361 ^^^No faces in D20100715-T182414094
</programlisting>

        <informalfigure>
          <para>This time we have a much higher percentage of good versus bad
          possible face detection.</para>
        </informalfigure>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Q400.jpg" scalefit="1" width="4in"></imagedata>
          </imageobject>
        </mediaobject>

        <para></para>
      </section>

      <section>
        <title>Faces with Eyes</title>

        <para>The next step for INDIface is looking in the area of the
        detected potential faces and detecting eyes and other features in
        preparation for INDIface template generation. Lets enable it and set a
        threshold to separate the "good" eye locations from the bad
        by<varname> /Generate/Enable=true</varname> and
        <varname>/Generate/MinConsistency=400</varname>. Also set
        /Output/MarkedDir=Marked so we can separate the good, the bad, and the
        ugly.</para>

        <informalfigure>
          <para>This time we got only "good" faces.</para>
        </informalfigure>

        <informalfigure>
          <para></para>
        </informalfigure>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/C400.jpg"></imagedata>
          </imageobject>
        </mediaobject>

        <informalfigure>
          <para>And what of the "marked" image?</para>

          <mediaobject>
            <imageobject>
              <imagedata fileref="art/D20100715-T183858550.JPG" scalefit="1"
                         width="5.5in"></imagedata>
            </imageobject>
          </mediaobject>
        </informalfigure>

        <para>The yellow boxes indicate the potential detected face location
        with the yellow eyes where we found the eyes; these were considered to
        be "good" enough faces to generate useful templates. The green boxes
        and eyes indicate the detected face and eye locations, but they fell
        (slightly) below the threshold for a good template. If there were
        potential faces detected (above the
        <varname>/Detect/Quality=400</varname> we set above), they would be
        indicated with blue boxes, as shown below:</para>

        <para><informalfigure>
            <para></para>
          </informalfigure><mediaobject>
            <imageobject>
              <imagedata fileref="art/D20100719-T135830352.JPG" scalefit="1"
                         width="5.5in"></imagedata>
            </imageobject>
          </mediaobject></para>
      </section>
    </section>

    <section>
      <title>Enrolling</title>

      <para></para>

      <section>
        <title>Gathering Faces for Enrollment</title>

        <para>The Face output directory contains faces that have been
        detected, confirmed as reasonably consistent, and had INDIface
        templates generated for them. (This also applies to the
        <filename>FaceCache</filename> and <filename>MarkedFace</filename>
        output directories as well). Gather up faces from these sources and
        separate them by person.</para>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/PS001037.png" scalefit="1" width="6in"></imagedata>
          </imageobject>
        </mediaobject>

        <note>
          <para>This directory is available in the SDK at
          <filename>./Sample/Input/SampleEnroll</filename>.</para>
        </note>
      </section>

      <section xml:id="chapGettingStarted-Enrolling">
        <title>Enrolling</title>

        <para>Set up a temporary enrollment directory and add the following to
        the current registry key:
        <varname>Enroll/InputDir=T:/Enroll</varname>.</para>

        <para>To enroll each person:</para>

        <orderedlist>
          <listitem>
            <para>Ensure the temporary enrollment directory is empty when you
            start.</para>
          </listitem>

          <listitem>
            <para>Copy five to ten distinctive images for one person to the
            temporary enrollment directory.</para>

            <mediaobject>
              <imageobject>
                <imagedata fileref="art/PS001038.png" scalefit="1" width="6in"></imagedata>
              </imageobject>
            </mediaobject>
          </listitem>

          <listitem>
            <para>Set <varname>Input/Pause=true</varname>; this isn't
            required, but will give more consistent time performance if you
            can pause regular input during enrollment.</para>
          </listitem>

          <listitem>
            <para>Set <varname>Enroll/PersonId=Williams,Juan</varname> and
            then set <varname>Enroll/Command=Enroll</varname> to start the
            enrollment process for Juan Williams.</para>

            <programlisting>-17:52:17.537 Enroll/Command changed to Enroll
+17:52:17.553 [ENROLL] Started
-17:52:17.611 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.643 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.675 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.707 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.755 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.787 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.819 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.851 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.884 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.916 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.948 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
-17:52:17.980 INDI EigenFace enrolled: 1 vector(s) 0 duplicates
+17:52:18.028 [ENROLL] Done - Results:
-17:52:18.028 PersonId=Williams,Juan PersonKey=126628
-17:52:18.028 D20090120-T111723687-X0355Y0199C520E066 enrolled as 126628:321929 Active
-17:52:18.028 D20090120-T111730640-X0335Y0191C515E070 enrolled as 126628:590766 Active
-17:52:18.028 D20090120-T111739640-X0364Y0193C433E071 enrolled as 126628:816254 Active
-17:52:18.028 D20090120-T111753671-X0378Y0194C446E073 enrolled as 126628:961995 Active
-17:52:18.028 D20090120-T111757656-X0393Y0186C409E073 enrolled as 126628:233770 Active
-17:52:18.028 D20090120-T111803656-X0394Y0199C402E054 enrolled as 126628:947711 Active
-17:52:18.030 D20090120-T113948640-X0348Y0186C408E071 enrolled as 126628:349037 Active
-17:52:18.030 D20090120-T114010656-X0346Y0181C413E054 enrolled as 126628:653962 Active
-17:52:18.030 D20090120-T114011671-X0381Y0192C520E069 enrolled as 126628:976974 Active
-17:52:18.030 D20090120-T114012671-X0368Y0183C534E070 enrolled as 126628:44626 Active
-17:52:18.030 D20090120-T114014687-X0302Y0193C463E066 enrolled as 126628:611922 Active
-17:52:18.030 D20090120-T114019656-X0342Y0194C410E055 enrolled as 126628:676765 Active
-17:52:18.560 Enroll/Command changed to 
</programlisting>
          </listitem>

          <listitem>
            <para>Wait for <varname>Enroll/Status</varname> to be "Done" or
            "Error". If "Done", monitor <varname>Enroll/Result</varname> for
            successful results. If "Error", <varname>Enroll/Reason</varname>
            will contain the basis of the error. Here is an example of an
            error, I mistakenly set
            <varname>Enroll/PersonKey=Williams,Juan</varname> and issued an
            enrollment command. It interpreted <varname>PersonKey</varname>
            (which should be numeric) as zero and <varname>PersonId</varname>
            was missing. Renaming the <varname>PersonKey</varname> to
            <varname>PersonId</varname> registry value succeeded and generated
            the results above.</para>

            <programlisting>-17:49:00.820 Enroll/Command changed to Enroll
+17:49:00.836 [ENROLL] Started
*17:49:00.836 IfSearchEnroll 311 [ENROLL] Error: PersonId must be specified for new person
-17:49:01.835 Enroll/Command changed to 
</programlisting>
          </listitem>
        </orderedlist>

        <para>Repeat for each person that you wish to enroll. This will fill
        your INDIbase (by default at <filename>../FaceBase</filename> relative
        to the directory where <command>IfSearch</command> is run,
        <filename>./INDIface/FaceBase</filename> relative to
        <filename>./INDIface/bin</filename>) with normalized face image files
        (FI folders), template XML files (FT folders), and person XML files
        (PR folders) as well as your internal matcher memory. For basic
        purposes, the FaceBase directory have no user serviceable parts
        inside.</para>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/PS001040.png" scalefit="1" width="7in"></imagedata>
          </imageobject>
        </mediaobject>

        <note>
          <para>This FaceBase data is available in the SDK at
          <filename>./INDIface/Input/SampleFaceBase</filename>.</para>
        </note>
      </section>
    </section>

    <section>
      <title>Matching</title>

      <para></para>

      <section>
        <title>Casual Matching</title>

        <para>Now that we have faces enrolled in an INDIbase, we can have the
        SDK compare each face found in every frame against all of the enrolled
        faces in the current INDIbase. This is not the most reliable form for
        accurate facial recognition, but allows your application to show some
        eye candy and may provide some useful data. To enable casual matching,
        set <varname>Match/Enable=true</varname>,
        <varname>Match/MinConfidence=500</varname>,
        <varname>Match/MaxResults=12</varname>,
        <varname>Output/ImageDir=Image</varname>, and
        <varname>Output/MatchDir=Match</varname>. You can point
        <varname>Input/URL</varname> to
        <filename>./Sample/Input/ObamaSpeach</filename> and, if you were
        paused while enrolling, set
        <varname>Input/Pause=false</varname>.</para>

        <para>In the Image output directory, you will find composite images
        with the face found in the current frame in the center surrounded by
        the (up to twelve) best matches starting at the upper left and
        continuing clockwise. Examples are:</para>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Composite4.png" scalefit="1" width="6in"></imagedata>
          </imageobject>
        </mediaobject>

        <para>In the following image, you will note that the automatic eye
        detection failed. (The left--as viewed by the camera--eye is on the
        ear and the right eye is on the left.) So, you will also note that the
        matching results are less than stellar.</para>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/D20090324-T170236921-X0317Y0156C442E065.JPG"
                       scalefit="1" width="2.3in"></imagedata>
          </imageobject>
        </mediaobject>

        <para>The individual enrolled normalized images of the closest
        enrolled match for each person matching the face from the current
        frame are also written to the Match output directory.</para>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/PS001041.png" scalefit="1" width="7in"></imagedata>
          </imageobject>
        </mediaobject>

        <para>In the image above, the highlighted file,
        <filename>D20090324-T170452250-X0350Y0150C666E053-R01.PNG</filename>,
        is the best enrolled match for the face found at 350,150 in the
        original image captured at 5:04:52.250 PM on March 24, 2009. The
        following ten files (-R02 to -R11) are the next best matches from the
        enrollment.</para>

        <section xml:id="secFormatSearch">
          <title>Formal Search</title>

          <para>The best results are obtained when you can gather a few faces
          of the same person for searching against the enrolled FaceBase.
          Create a temporary directory, place a few faces (gathered from
          <varname>FaceDir</varname>, <varname>FaceCacheDir</varname>, or
          <varname>MarkedFaceDir</varname>) in the directory, and set
          Search/InputDir to point to that directory. You can set parameters
          such as <varname>MaxResults</varname> or
          <varname>MinConfidence</varname> to limit the results and you can
          set <varname>OutputDir</varname> to receive enrolled face results.
          Then set <varname>Search/Command=Search</varname> and wait for
          <varname>Search/Status</varname> to be "Done" or "Error".
          <varname>Search/Reason</varname> will explain an "Error" or
          <varname>Search/Results</varname> will contain the results if
          "Done".</para>

          <para><programlisting>-18:23:43.585 Input/Pause changed to 1
-18:26:43.073 Search/OutputDir changed to T:\SearchOutput
-18:26:43.120 Search directory set to T:/SearchOutput
-18:27:46.958 Search/Command changed to Search
+18:27:46.974 [SEARCH] Started for Search
-18:27:47.132 [SEARCH] 44 writes pending
-18:27:47.244 [SEARCH] 41 writes pending
-18:27:47.362 [SEARCH] 34 writes pending
-18:27:47.474 [SEARCH] 31 writes pending
-18:27:47.573 [SEARCH] 25 writes pending
-18:27:47.689 [SEARCH] 19 writes pending
-18:27:47.804 [SEARCH] 13 writes pending
-18:27:47.920 [SEARCH] 7 writes pending
-18:27:48.034 [SEARCH] 1 writes pending
+18:27:48.145 [SEARCH] Done - Results:
-18:27:48.145 
-18:27:48.145 D20090119-T200050562-X0169Y0244C583E087.PNG search image Active
-18:27:48.145 D20090119-T200109578-X0234Y0192C573E044.PNG search image Active
-18:27:48.145 D20090119-T200114562-X0269Y0189C623E034.PNG search image Active
-18:27:48.145 D20090119-T200115609-X0386Y0184C680E046.PNG search image Active
-18:27:48.145 D20090119-T200441593-X0284Y0258C506E126.PNG search image Active
-18:27:48.145 10 results
-18:27:48.145  1. 793   316057 Hume,Brit
-18:27:48.145  2. 793   970578 Biden,Joe
-18:27:48.145  3. 789    98797 Obama,Barak
-18:27:48.145  4. 773   707299 Baer,Brett
-18:27:48.145  5. 728   126628 Williams,Juan
-18:27:48.145  6. 710    59290 Obama,Michelle
-18:27:48.145  7. 682   305166 Smith,Sheppard
-18:27:48.145  8. 642   657519 Reid,Harry
-18:27:48.145  9. 593   837859 Guilianni,Rudy
-18:27:48.145 10. 548   170123 GeicoGuy
-18:27:48.988 Search/Command changed to 
</programlisting></para>

          <para>The "Verify" and "VerifyList" (future) commands can be used to
          limit the results to one person or a handful of enrolled persons of
          interest.</para>
        </section>
      </section>

      <section xml:id="chapGettingStarted-Search">
        <title>Formal Search</title>

        <para>The best results are obtained when you can gather a few faces of
        the same person for searching against the enrolled FaceBase. Create a
        temporary directory, place a few faces (gathered from
        <varname>FaceDir</varname>, <varname>FaceCacheDir</varname>, or
        <varname>MarkedFaceDir</varname>) in the directory, and set
        Search/InputDir to point to that directory. You can set parameters
        such as <varname>MaxResults</varname> or
        <varname>MinConfidence</varname> to limit the results and you can set
        <varname>OutputDir</varname> to receive enrolled face results. Then
        set <varname>Search/Command=Search</varname> and wait for
        <varname>Search/Status</varname> to be "Done" or "Error".
        <varname>Search/Reason</varname> will explain an "Error" or
        <varname>Search/Results</varname> will contain the results if
        "Done".</para>

        <para><programlisting>-18:23:43.585 Input/Pause changed to 1
-18:26:43.073 Search/OutputDir changed to T:\SearchOutput
-18:26:43.120 Search directory set to T:/SearchOutput
-18:27:46.958 Search/Command changed to Search
+18:27:46.974 [SEARCH] Started for Search
-18:27:47.132 [SEARCH] 44 writes pending
-18:27:47.244 [SEARCH] 41 writes pending
-18:27:47.362 [SEARCH] 34 writes pending
-18:27:47.474 [SEARCH] 31 writes pending
-18:27:47.573 [SEARCH] 25 writes pending
-18:27:47.689 [SEARCH] 19 writes pending
-18:27:47.804 [SEARCH] 13 writes pending
-18:27:47.920 [SEARCH] 7 writes pending
-18:27:48.034 [SEARCH] 1 writes pending
+18:27:48.145 [SEARCH] Done - Results:
-18:27:48.145 
-18:27:48.145 D20090119-T200050562-X0169Y0244C583E087.PNG search image Active
-18:27:48.145 D20090119-T200109578-X0234Y0192C573E044.PNG search image Active
-18:27:48.145 D20090119-T200114562-X0269Y0189C623E034.PNG search image Active
-18:27:48.145 D20090119-T200115609-X0386Y0184C680E046.PNG search image Active
-18:27:48.145 D20090119-T200441593-X0284Y0258C506E126.PNG search image Active
-18:27:48.145 10 results
-18:27:48.145  1. 793   316057 Hume,Brit
-18:27:48.145  2. 793   970578 Biden,Joe
-18:27:48.145  3. 789    98797 Obama,Barak
-18:27:48.145  4. 773   707299 Baer,Brett
-18:27:48.145  5. 728   126628 Williams,Juan
-18:27:48.145  6. 710    59290 Obama,Michelle
-18:27:48.145  7. 682   305166 Smith,Sheppard
-18:27:48.145  8. 642   657519 Reid,Harry
-18:27:48.145  9. 593   837859 Guilianni,Rudy
-18:27:48.145 10. 548   170123 GeicoGuy
-18:27:48.988 Search/Command changed to 
</programlisting></para>

        <para>The "Verify" and "VerifyList" (future) commands can be used to
        limit the results to one person or a handful of enrolled persons of
        interest.</para>
      </section>
    </section>

    <section>
      <title>Managing</title>

      <para></para>

      <section>
        <title>INDIbase Retrieval</title>

        <para>To retrieve enrollments from the FaceBase, use the Retrieve
        commands. If you want the images and Person XML files, set
        <varname>Retrieve/OutputDir</varname> (to
        <filename>F:/INDIout/@/Retrieve</filename> in this example). Set
        <varname>Retrieve/PersonId</varname> (to "Obama,Barak" in this
        example) and set <varname>Retrieve/Command=Retrieve</varname>. Wait
        for <varname>Retrieve/Status</varname> to be either "Done", "Error",
        or "NotFound". If "Done", you will find the results in
        <varname>Retrieve/Results</varname> and, if set, files in the retrieve
        directory. If "Error", the reason will be in
        <varname>Retrieve/Reason</varname>.</para>

        <para><programlisting>-16:33:08.885 Retrieve/Command changed to Retrieve
+16:33:08.895 [RETRIEVE] Started
-16:33:08.984 [RETRIEVE] 16 writes pending
-16:33:09.085 [RETRIEVE] 16 writes pending
-16:33:09.197 [RETRIEVE] 16 writes pending
-16:33:09.308 [RETRIEVE] 16 writes pending
.16:33:09.351 IfSearchSlots 36  0 grabs in cache
~16:33:09.355 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/PR098797.xml written
.16:33:09.355 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/PR098797.xml
~16:33:09.460 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI097748.PNG written
.16:33:09.460 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI097748.PNG
-16:33:09.462 [RETRIEVE] 14 writes pending
~16:33:09.534 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI134173.PNG written
.16:33:09.535 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI134173.PNG
-16:33:09.570 [RETRIEVE] 13 writes pending
~16:33:09.593 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI288062.PNG written
.16:33:09.593 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI288062.PNG
.16:33:09.594 ImageSource 240 Paused
~16:33:09.661 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI312767.PNG written
.16:33:09.662 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI312767.PNG
-16:33:09.679 [RETRIEVE] 11 writes pending
~16:33:09.741 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI368784.PNG written
.16:33:09.741 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI368784.PNG
-16:33:09.788 [RETRIEVE] 10 writes pending
~16:33:09.807 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI374828.PNG written
.16:33:09.807 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI374828.PNG
.16:33:09.850 ImageSource 240 Paused
~16:33:09.882 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI476155.PNG written
.16:33:09.882 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI476155.PNG
.16:33:09.883 IfSearchSlots 36  0 grabs in cache
-16:33:09.897 [RETRIEVE] 8 writes pending
~16:33:09.961 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI557232.PNG written
.16:33:09.961 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI557232.PNG
-16:33:10.011 [RETRIEVE] 7 writes pending
~16:33:10.034 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI565060.PNG written
.16:33:10.034 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI565060.PNG
~16:33:10.088 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI573688.PNG written
.16:33:10.088 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI573688.PNG
-16:33:10.115 [RETRIEVE] 5 writes pending
.16:33:10.115 ImageSource 240 Paused
~16:33:10.148 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI607696.PNG written
.16:33:10.148 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI607696.PNG
~16:33:10.224 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI624506.PNG written
.16:33:10.224 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI624506.PNG
-16:33:10.225 [RETRIEVE] 3 writes pending
~16:33:10.291 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI664819.PNG written
.16:33:10.291 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI664819.PNG
-16:33:10.334 [RETRIEVE] 2 writes pending
~16:33:10.356 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI671731.PNG written
.16:33:10.356 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI671731.PNG
~16:33:10.414 FileWriter 458 Retrieve file: F:/INDIout/D20110319-T1627/Retrieve/FI967365.PNG written
.16:33:10.414 IfSearchSlots 109 Wrote F:/INDIout/D20110319-T1627/Retrieve/FI967365.PNG
+16:33:10.445 [RETRIEVE] Done - Results:
-16:33:10.445 Person: 98797=Obama,Barak
-16:33:10.445    Face: 54224=D20090120-T115145671-X0275Y0145C563E035 {Deleted}
-16:33:10.445    Face: 97748=D20090120-T132402781-X0439Y0104C413E036 {Active}
-16:33:10.445    Face: 134173=D20090120-T130606078-X0207Y0177C513E029 {Active}
-16:33:10.445    Face: 288062=D20090120-T130555078-X0352Y0183C510E044 {Active}
-16:33:10.445    Face: 312767=D20090120-T202239906-X0333Y0217C581E068 {Active}
-16:33:10.445    Face: 368784=D20090120-T115637640-X0364Y0170C701E057 {Active}
-16:33:10.445    Face: 374828=D20090120-T115109671-X0256Y0155C685E032 {Active}
-16:33:10.445    Face: 476155=D20090120-T203144906-X0409Y0185C421E064 {Active}
-16:33:10.448    Face: 557232=D20090120-T130557062-X0334Y0186C720E039 {Active}
-16:33:10.448    Face: 565060=D20090120-T115213640-X0370Y0156C732E051 {Active}
-16:33:10.448    Face: 573688=D20090120-T203701937-X0312Y0137C520E043 {Active}
-16:33:10.448    Face: 607696=D20090120-T115215671-X0359Y0167C655E037 {Active}
-16:33:10.448    Face: 624506=D20090120-T115231656-X0385Y0170C634E051 {Active}
-16:33:10.448    Face: 664819=D20090120-T204523906-X0313Y0122C576E036 {Active}
-16:33:10.448    Face: 671731=D20090120-T115154687-X0313Y0189C562E032 {Active}
-16:33:10.448    Face: 967365=D20090120-T115108640-X0231Y0154C462E030 {Active}
</programlisting><mediaobject>
            <imageobject>
              <imagedata fileref="art/PS004380.png" scalefit="1" width="6in"></imagedata>
            </imageobject>
          </mediaobject><programlisting>&lt;!DOCTYPE INDIface-Person&gt; &lt;PersonRecord Active="1" PersonKey="98797"&gt; &lt;Id&gt;Obama,Barak&lt;/Id&gt; &lt;/PersonRecord&gt; </programlisting></para>
      </section>

      <section>
        <title>Enrollment Management</title>

        <para>To delete a face from active matching, you can use the "Delete"
        command for enrollment. Set <varname>Enroll/PersonId</varname> (to
        "Obama,Barak" in this example) for faces that were enrolled to a
        person and <varname>Enroll/FaceId</varname> (to
        "D20090120-T115145671-X0275Y0145C563E035" in this example) and then
        set <varname>Enroll/Command=Delete</varname>. Wait for
        <varname>Status</varname> to be "Done" or "Error" and check either
        <varname>Enroll/Results</varname> or
        <varname>Enroll/Reason</varname>.</para>

        <para><programlisting>-15:58:52.306 Enroll/Command changed to Delete 
+15:58:52.316 [ENROLL] Started for Delete Face 
~15:58:52.319 EigenFaceFace 112 Face written: D:/SVN2/trunk/EclipseIR/FaceBase/FT054/FT054224.xml 
+15:58:52.331 [ENROLL] Done - Results: 
-15:58:52.331 Deleted FaceKey=54224 FaceId=D20090120-T115145671-X0275Y0145C563E035 PersonKey=98797 PersonId=Obama,Barak</programlisting></para>

        <para>You also have the option to remove all face enrollments for a
        person with the "Remove" command or set a new
        <varname>PersonId</varname> with the "Rename" command. The "RemoveAll"
        command can be used to erase a FaceBase.</para>
      </section>
    </section>
  </chapter>

  <chapter>
    <title>Control Parameter Reference</title>

    <para>There are over 140 control parameters that you can use to tailor the
    SDK's actions. The control variables are broken into sections that
    correspond to their key in the registry (or section of an XML
    configuration file in the future).</para>

    <variablelist>
      <varlistentry>
        <term>Clothes</term>

        <listitem>
          <para>Clothes color matching</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Detect</term>

        <listitem>
          <para>Face detection</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>FaceBase</term>

        <listitem>
          <para>Enrolled person records, face templates, and face
          images.</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>FaceColor</term>

        <listitem>
          <para>Face skin tone detection</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Generate</term>

        <listitem>
          <para>Template generation</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Height</term>

        <listitem>
          <para>Approximate height detection</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Input</term>

        <listitem>
          <para>Image acquisition</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Mark</term>

        <listitem>
          <para>Image marking colors and attributes</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Match</term>

        <listitem>
          <para>Informal matching</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Options</term>

        <listitem>
          <para>Operation of the SDK executable itself</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Output</term>

        <listitem>
          <para>Location of output files and method of marking marked
          files</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>PreProcess</term>

        <listitem>
          <para>Transformation</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>Resolve</term>

        <listitem>
          <para>Controls for combining the face-based analytics.</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <note>
      <para>The Enroll, Retrieve, and Search keys in the registry will be
      discussed in the next chapter.</para>
    </note>

    <section>
      <title>Command Line</title>

      <para>When we utilize the Windows registry, controls are placed in the
      HKCU/Software section of the registry under <varname>OrgName</varname>
      and <varname>AppName</varname> keys. The default is
      <filename>HKCU/Software/EclipseIR/IfSearch</filename> but it can be
      specified on the command line as <command>%OrgName/AppName</command> or
      <command>%AppName</command>. Control parameters can be specified on the
      command line, and will override what is read from the registry, in the
      form <command>/Key/Name=Value</command>. Examples include
      <userinput>/Input/URL=http://demo:demo@192.168.1.90/jpg/image.jpg</userinput>
      to specify a different camera or
      <filename>/FaceBase/BaseDir=W:/herever/else</filename> could be used to
      load a different INDIbase for matching.</para>
    </section>

    <section>
      <title>Control Types</title>

      <para>The controls are strings (URLs, directory names, file names,
      etc.), numbers, booleans, or colors. All can be in REG_SZ format in the
      Windows registry. Integer numbers can be in REG_DWORD format.</para>

      <section xml:id="secSpecifyingOutputDirectories">
        <title>Specifying Directories</title>

        <para>All input or output directories can be specified in absolute
        (starting from the root) or relative (from a base directory) terms.
        The Output/BaseDir control parameter can be used to specify a the base
        directory upon which all other input or output directories can be
        specified in relative terms. In addition, it can be relative to the
        current directory at the time that the SDK console was started. An at
        sign (@) can be specified anywhere in the directory name and it will
        be replaced by the time stamp of when the console was started in
        "Dyyyymmdd-Thhmm" format.</para>

        <note xml:id="noteMultipleOutputDirs">
          <para>Multiple output directories for the same class of files can be
          specified, delimited with a semicolon.</para>
        </note>
      </section>

      <section xml:id="secSpecifyingColors">
        <title xml:id="titleSpecifyingColors">Specifying Colors</title>

        <para>Colors can be specified in three ways.</para>

        <itemizedlist>
          <listitem>
            <para>A blank entry (value name present, but empty data in the
            registry) will be interpreted as an "empty" color which will
            disable the particular function.</para>
          </listitem>

          <listitem>
            <para>A string value in the form #RRGGBB to specify RR as two hex
            digits for red, GG for green, and BB for blue. The hash sign is
            required.</para>
          </listitem>

          <listitem>
            <para>A string value with a named SVG color, such as "black"
            "salmon" or "blanchedalmond". See the W3 SVG standard for a list
            of named colors.</para>
          </listitem>
        </itemizedlist>

        <note>
          <para>If an entry is missing (not present at all in the registry),
          then the default specified for the control below is used. If no
          default is specified then that item would be disabled.</para>
        </note>
      </section>

      <section>
        <title>Specifying Booleans</title>

        <para>Boolean values can be specified as REG_SZs with "true" or "1"
        versus "false" or "0". They can also be specified as REG_DWORDs with
        value zero or one. Other combinations may work, but have not been
        tested.</para>
      </section>
    </section>

    <section xml:id="secClothesColor">
      <title>Clothes Color Controls</title>

      <para>If clothes color testing is enabled, once the eyes have been
      located and confirmed to match a reasonable face template, the location
      in the input image of the upper and lower parts of the body are
      estimated. The predominate characteristic color is then collected from
      both of those areas to the extent they are present in the input image. A
      confidence value is calculated for each area based upon the
      preponderance of pixels that are near the specified target
      colors.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="art/ErinAndrews-Clothes.jpg" scalefit="1"
                     width="3in"></imagedata>
        </imageobject>
      </mediaobject>

      <para>The shoulder, waist, and ankle controls are used to estimate the
      vertical boundaries of the upper and lower body rectangles. The width
      control provides the horizontal size of those rectangles. These values
      are basically in number of millimeters below the center of the face
      (nose tip). The UnderCrop control is used to determine how far inside
      the upper/lower body rectangles is sampled for characteristic
      color.</para>

      <para>The calling application provides a target color and minimum
      confidence level for either or both upper and lower clothes. If the
      colors match above the specified confidence levels, it is considered a
      match and an input image with the face marked is written to the Clothes
      output directory.</para>

      <note>
        <para>If both upper and lower confidence values are specified, both
        have to be present in the input image for a match to be
        declared.</para>
      </note>

      <para>The following images show the matches at 900, 800, and 700 to the
      background color of the image.</para>

      <figure>
        <title>Pink 900 Confidence</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Pink900.png" scalefit="1" width="6in"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Pink 800 Confidence</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Pink800.png" scalefit="1" width="6in"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Pink 700 Confidence</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Pink700.png" scalefit="1" width="6in"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Navy 700 Confidence</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/Navy700.png" scalefit="1" width="6in"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <section>
        <title>Ankle</title>

        <para>The approximate distance below the center of the detected face
        for the lower boundary of the lower clothes color sampling in
        millimeters.</para>

        <para>Special Value: 0 translates to 1536.</para>

        <para>Default: 0 (translates to 1536mm or approximately 5
        feet).</para>
      </section>

      <section>
        <title>Enable</title>

        <para>Set to true to enable upper or lower clothes color
        detection.</para>

        <para>Default: false (disabled).</para>
      </section>

      <section>
        <title>LowerColor</title>

        <para>The target color for the lower clothes color. See also <link
        linkend="secSpecifyingColors">Specifying Colors</link> above.</para>

        <para>Default: none (Upper clothes color is not tested for
        match.)</para>
      </section>

      <section>
        <title>LowerConfidence</title>

        <para>The minimum confidence level accepted for a match of the
        detected lower clothes color to the specified target from 1 to
        999.</para>

        <para>Default: 0 (Lower clothes color is not tested for match.)</para>
      </section>

      <section>
        <title>Shoulder</title>

        <para>The approximate distance below the center of the detected face
        for the upper boundary of the upper clothes color sampling in
        millimeters.</para>

        <para>Special Value: 0 translates to 128.</para>

        <para>Default: 0 (translates to 128mm or approximately 5
        inches).</para>
      </section>

      <section>
        <title>UnderCrop</title>

        <para>The percentage that the rectangles determined by Ankle, Waist,
        Shoulder, and Width will be reduced for characteristic color
        sampling.</para>

        <para>Special Value: 0 translates to 80.</para>

        <para>Default: 0 (translates to 80%).</para>
      </section>

      <section>
        <title>UpperColor</title>

        <para>The target color for the lower clothes color. See also <link
        linkend="secSpecifyingColors">Specifying Colors</link> above.</para>

        <para>Default: none (Upper clothes color is not tested for
        match.)</para>
      </section>

      <section>
        <title>UpperConfidence</title>

        <para>The minimum confidence level accepted for a match of the
        detected upper clothes color to the specified target from 1 to
        999.</para>

        <para>Default: 0 (Upper clothes color is not tested for match.)</para>
      </section>

      <section>
        <title>Waist</title>

        <para>The approximate distance below the center of the detected face
        for the boundary between the upper and lower clothes color sampling in
        millimeters.</para>

        <para>Special Value: 0 translates to 512.</para>

        <para>Default: 0 (translates to 512mm or approximately 20
        inches).</para>
      </section>

      <section>
        <title>Width</title>

        <para>The approximate width of the upper and lower clothes color
        sampling area in millimeters.</para>

        <para>Special Value: 0 translates to 256.</para>

        <para>Default: 0 (translates to 256).</para>
      </section>
    </section>

    <section>
      <title>Detect Controls</title>

      <para>The <varname>MinAcross</varname>, <varname>MaxAcross</varname>,
      and <varname>Factor</varname> controls affect how the raw detectors are
      generated and are interpreted. <varname>MinAcross</varname> and
      <varname>MaxAcross</varname> are the inverse of
      <varname>MaxPixels</varname> and <varname>MinPixels</varname> and are
      scaled by the width of the image. They basically specify the minimum and
      maximum number of people shoulder to shoulder expected in a frame. At
      default (<varname>MinAcross=0</varname> and
      <varname>MaxAcross=0</varname>), the raw detectors can range from their
      base size (typically 20x20 to 32x32 pixels) up to the size of the entire
      frame. In this case, they may detect many false positives: undersize,
      oversize, or both.</para>

      <para><figure>
          <title>Detect: MinAcross=0 MaxAcross=0</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="art/Detect-Min0Max0.jpg" scalefit="1"
                         width="6.5in"></imagedata>
            </imageobject>
          </mediaobject>
        </figure>Pretending that this is a camera watching an entrance and we
      expect that people generally are walking in at six abreast, we can set
      <varname>MaxAcross=8</varname> just to be safe. Doing that eliminates
      the many tiny false positive detections.</para>

      <note>
        <para>This also saves CPU resources by starting the raw detectors at
        an appropriate size.</para>
      </note>

      <para><figure>
          <title>Detect: MinAcross=0, MaxAcross=8</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="art/Detect-Min0Max8.jpg" scalefit="1"
                         width="6.5in"></imagedata>
            </imageobject>
          </mediaobject>
        </figure>Now, we can eliminate the two very oversize detections by
      setting <varname>MinAcross=4</varname>.</para>

      <para><figure>
          <title>Detect: MinAcross=4, MaxAcross=8</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="art/Detect-Min4Max8.jpg" scalefit="1"
                         width="6.5in"></imagedata>
            </imageobject>
          </mediaobject>
        </figure>The detectors are appropriately sized now, so we are not
      using excessive CPU. We can afford to increase the Factor from the
      default 10 to 5 and get back the missing face.</para>

      <para><figure>
          <title>Detect: MinAcross=4, MaxAcross=8, Factor=5</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="art/Detect-Factor5.jpg" scalefit="1"
                         width="6.5in"></imagedata>
            </imageobject>
          </mediaobject>
        </figure></para>

      <section>
        <title>CharcolDir</title>

        <para>Enabling this directory will output a diagnostic image of the
        entire input frame converted to characteristic colors that are used
        for clothes detection. See also <link
        linkend="secSpecifyingOutputDirectories">Specifying
        Directories</link>.</para>

        <para>Default: blank (output disabled)</para>
      </section>

      <section>
        <title>DetectorsXml</title>

        <para>This specifies the location of the XML file that identifies and
        locates the various object detectors.</para>

        <warning>
          <para>This is not a volatile value: It is used at startup and
          changes are ignored.</para>
        </warning>

        <para>Default: <filename>../Detectors/Detectors.XML</filename></para>
      </section>

      <section>
        <title>Enable</title>

        <para>Set this value to true to enable frontal face detection. If
        disabled, the SDK will assume that the entire input frame contains a
        face using <varname>InputOverCrop</varname> to scale the detected
        face.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>Factor</title>

        <para>Specifies the factor by which raw detectors width are increased
        in each pass over the input image; this value divided by 100 is added
        to 1.0. Smaller numbers yield greater accuracy at the cost of more
        processing time. Larger numbers yield faster processing with the
        greater possibility of false positive and false negative detections.
        Typical values are 0.5 (1.005) to 20 (1.20).</para>

        <para><figure>
            <title>Detect/Factor default (10)</title>

            <mediaobject>
              <imageobject>
                <imagedata fileref="art/FactorDefault.JPG" scalefit="1"
                           width="6in"></imagedata>
              </imageobject>
            </mediaobject>
          </figure><figure>
            <title>Detect/Factor=5 (denser)</title>

            <mediaobject>
              <imageobject>
                <imagedata fileref="art/Factor5.JPG" scalefit="1" width="6in"></imagedata>
              </imageobject>
            </mediaobject>
          </figure><figure>
            <title>Detect/Factor=15 (sparser)</title>

            <mediaobject>
              <imageobject>
                <imagedata fileref="art/Factor15.JPG" scalefit="1" width="6in"></imagedata>
              </imageobject>
            </mediaobject>
          </figure></para>

        <para>Special value: 0.0 translates to 10.0 (1.10).</para>

        <para>Default: 0.0 (1.10).</para>
      </section>

      <section>
        <title>ForceFind</title>

        <para>Depricated. Will be removed in future versions.</para>
      </section>

      <section>
        <title>GroupMethod</title>

        <para>Specifies how raw face detectors will be grouped to identify a
        possible face. Set to one of the follow values (or leave it
        zero):</para>

        <orderedlist>
          <listitem>
            <para>GroupByCenters</para>
          </listitem>

          <listitem>
            <para>GroupByOverlap</para>
          </listitem>

          <listitem>
            <para>GroupByNeighbors</para>
          </listitem>

          <listitem>
            <para>GroupInternal</para>
          </listitem>

          <listitem>
            <para>GroupInternalAllObjects</para>
          </listitem>
        </orderedlist>

        <para>Default: zero (let the engine decide)</para>
      </section>

      <section>
        <title>GroupThreshold</title>

        <para>Future: Controls the detection threshold for GroupMethod=4
        (GroupInternal) or 5 (GroupInternalAllObjects)</para>
      </section>

      <section>
        <title>InputOverCrop</title>

        <para>This value is used when <varname>Detect/Enable=false</varname>.
        In the case when processing a set of images where face detection has
        already taken place. This value should match
        <varname>Output/MarkOverCrop</varname> when the previous face
        detection was processed.</para>

        <para>Default: zero</para>
      </section>

      <section>
        <title>Interface</title>

        <para>Internal control. Leave at the default (zero) unless directed by
        an EIRC representative.</para>
      </section>

      <section>
        <title>MaxAcross</title>

        <para>The maximum number of people expected in a video frame standing
        shoulder to shoulder. The minimum detector size is calculated from
        this value.</para>

        <para>Special value: zero uses the minimum detector size
        available.</para>

        <para>Default: zero</para>
      </section>

      <section>
        <title>MaxPixels</title>

        <para>The maximum size of the detector in pixels.</para>

        <para>Special value: zero allows the detector to grow to the smallest
        dimension of the input frame.</para>

        <para>Default: zero</para>
      </section>

      <section>
        <title>MaxResults</title>

        <para>The maximum number of potential face detections per
        frame.</para>

        <para>Default: zero (no limit)</para>
      </section>

      <section>
        <title>MinAcross</title>

        <para>The minimum number of people expected in a video frame standing
        shoulder to shoulder. The maximum detector size is calculated from
        this value.</para>

        <para>Default: zero (no <varname>MaxPixels</varname>)</para>
      </section>

      <section>
        <title>MinPixels</title>

        <para>The minimum size of the detector.</para>

        <para>Default: zero (use the smallest detector available)</para>
      </section>

      <section>
        <title>MinQuality</title>

        <para>Sets the minimum quality of face detection that will be allowed
        on a scale from 1 to 999.</para>

        <para>Default: zero</para>
      </section>

      <section>
        <title>NeighborThreshold</title>

        <para>Future: Controls the detection threshold for GroupMethod=3
        (GroupByNeighbors)</para>
      </section>

      <section>
        <title>OverlapThreshold</title>

        <para>Future: Controls the detection threshold for GroupMethod=2
        (GroupByOverlap)</para>
      </section>

      <section>
        <title>SkinDir</title>

        <para>Enabling this directory will output a diagnostic image of the
        entire input frame masked to show only detected skin areas. See also
        <link linkend="secSpecifyingOutputDirectories">Specifying
        Directories</link> below.</para>

        <para>Default: empty (output disabled)</para>
      </section>
    </section>

    <section>
      <title>FaceBase controls</title>

      <section>
        <title>BaseDir</title>

        <para>Specifies the base directory for a file-based INDIbase storage
        of faces, templates, images, and person records. No user serviceable
        parts inside.</para>

        <para>Default: ../FaceBase</para>
      </section>

      <section>
        <title>MaxLoad</title>

        <para>Limits the number of enrollments that are loaded in
        memory.</para>

        <tip>
          <para>This is typically only used while debugging and developing to
          reduce facial database load time.</para>
        </tip>

        <para>Special Value: 0 (no limit)</para>

        <para>Default: 0 (no limit)</para>
      </section>
    </section>

    <section>
      <title>FaceColor Controls</title>

      <para>If enabled, the skin tone of the cheeks, nose, and forehead are
      collected.</para>

      <para><mediaobject>
          <imageobject>
            <imagedata fileref="art/ErinAndrews-Face.png" width="2.5in"></imagedata>
          </imageobject>
        </mediaobject>An application can then specify one or more named skin
      colors (such as "African" "Asian" "Anglo") to be compared with the
      detected data. The named color becomes a key in the
      <varname>FaceColor</varname> section of the registry. Within each of
      those keys, a <varname>TargetColor</varname>, a
      <varname>MinConfidence</varname> value, and an
      <varname>OutputDir</varname> are expected.</para>

      <para>When a face is detected and a consistent template can be
      generated, the collected skin tone color is compared against each of the
      specified target colors. If any of the matches are above the individual
      specified minimum confidence levels, the normalized face image is
      written to the output directory of the closest matching color.</para>

      <section>
        <title>Enable</title>

        <para>Set to true to enable face color detection.</para>

        <para>Default: false (disabled).</para>
      </section>

      <section>
        <title>MinConfidence</title>

        <para>The minimum confidence level from 1 to 999 that will allow that
        color to be considered the best match.</para>

        <para>Default: zero (any confidence will be considered)</para>
      </section>

      <section>
        <title>OutputDir</title>

        <para>The directory where the normalized face image will be written if
        this named color is considered the best match.</para>

        <para>Default: none (nothing written)</para>
      </section>

      <section>
        <title>TargetColor</title>

        <para>The target color for a particular named skin color.</para>

        <para>Default: none (disabled)</para>
      </section>
    </section>

    <section>
      <title>Generate Controls</title>

      <section>
        <title>DataDir</title>

        <para>Specifies the directory where INDIface XML datafiles will be
        loaded.</para>

        <warning>
          <para>This is not a volatile value: It is used at initialization and
          changes are ignored.</para>
        </warning>

        <para>Default: <filename>../Data/Face1</filename></para>
      </section>

      <section>
        <title>Enable</title>

        <para>Enables feature location and template generation.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>EyeScale</title>

        <para>Can be used to adjust the minimum and maximum sizes of the eye
        detectors in percent. Larger numbers (&gt; 100) will decrease the
        variation in eye size detectors; smaller numbers (&lt;100) will
        increase it the range.</para>

        <para>Default: zero (use default eye detector range)</para>
      </section>

      <section>
        <title>LeftDetector</title>

        <para>The name of an eye detector to be used for the (camera) left
        eye.</para>

        <para>Default: empty (use default)</para>
      </section>

      <section>
        <title>LeftInterface</title>

        <para>Internal control. Leave at the default (zero) unless directed by
        an EIRC representative.</para>
      </section>

      <section>
        <title>MinConsistency</title>

        <para>The minimum consistency on a scale from 1 to 999 that will
        generate a template for searching or enrollment.</para>

        <para>Default: zero</para>
      </section>

      <section>
        <title>OutputDir</title>

        <para>Specifies a directory to receive diagnostic face detection
        images. See <link linkend="secSpecifyingOutputDirectories">Specifying
        Directories</link>.</para>

        <para>Default: empty (no output)</para>
      </section>

      <section>
        <title>RightDetector</title>

        <para>The name of an eye detector to be used for the (camera) right
        eye.</para>

        <para>Default: empty (use default)</para>
      </section>

      <section>
        <title>RightInterface</title>

        <para>Internal control. Leave at the default (zero) unless directed by
        an EIRC representative.</para>
      </section>

      <section>
        <title>RoiScale</title>

        <para>Can be used to adjust the size of the region of the detected
        face where the eyes are expected in percent. Larger numbers (&gt; 100)
        will decrease the size of the region; smaller numbers (&lt;100) will
        decrease it. Typically this can be set to 150 in cases where large
        amounts of head roll are expected. It could be decreased slightly
        below 100 in cases where the faces are from "passport quality"
        images.</para>

        <para>Default: zero (no adjustment)</para>
      </section>
    </section>

    <section xml:id="secHeightControls">
      <title>Height Controls</title>

      <para>For fixed camera positions, a grid can be calibrated to provide an
      estimate of the height of a person standing a target distance away from
      the camera as scaled by the detected distance between the eyes.
      <mediaobject>
          <imageobject>
            <imagedata fileref="art/GridImage.png"></imagedata>
          </imageobject>
        </mediaobject></para>

      <para>For this example, <varname>GridCols=3</varname>,
      <varname>GridRows=7</varname>, and <varname>GridFile</varname> points to
      a file (<filename>GridFile.cdf</filename>) that contains the following,
      and <varname>TargetEyePixels=62</varname>.</para>

      <programlisting>0 0 0 
0 74 0 
0 68 0 
0 62 0 
0 56 0 
0 50 0 </programlisting>

      <section>
        <title>Enable</title>

        <para>Set true to enable height estimation processing. You must set
        <varname>GridCols</varname> and <varname>GridRows</varname> then
        specify a <varname>GridFile</varname> before the results will be
        calculated.</para>

        <para>Default: false (no height estimation)</para>
      </section>

      <section>
        <title>GridCols</title>

        <para>Specifies the number of columns expected in the
        <varname>GridFile</varname>.</para>

        <para>Default: zero (not used)</para>
      </section>

      <section>
        <title>GridFile</title>

        <para>Provides the location of a file containing the height values (in
        inches or centimeters) for each grid row and column. The file must
        have numeric entries for each (rows * cols) cell. Specify
        <varname>GridCols</varname> and <varname>GridRows</varname> before
        changing this value.</para>

        <para>Default: none (not used)</para>
      </section>

      <section>
        <title>GridRows</title>

        <para>Specifies the number of rows expected in the
        <varname>GridFile</varname>.</para>
      </section>

      <section>
        <title>HeightScale</title>

        <para>Adjusts the estimation of the top of the head. If the camera is
        significantly above the subjects heads, you may want to decrease the
        value to allow for image foreshortening. Specify in per cent.</para>

        <para>Default: zero (1.0)</para>
      </section>

      <section>
        <title>HeightUnits</title>

        <para>Sets the units that are specified in the grid file and in
        TargetHeight. This parameter allows the height confidence to be
        independent of the units units used. It is basically the number of
        millimeters in the unit specified. For example: 10 for centimeters, 25
        for inches, or 305 for feet.</para>

        <para>Added: v1.71A</para>

        <para>Default: 25 (inches)</para>
      </section>

      <section>
        <title>MinConfidence</title>

        <para>The minimum confidence level that will be considered a height
        match for output to the <varname>Output/HeightDir</varname>.</para>

        <para>Default: zero (anything matches)</para>
      </section>

      <section>
        <title>MinConsistency</title>

        <para>The minimum template generation consistency that will be
        submitted for height estimation.</para>

        <para>Default: zero (try anything that passed
        <varname>Generate/MinConsistency</varname>)</para>
      </section>

      <section>
        <title>TargetEyePixels</title>

        <para>The expected number of pixels between the eyes at the target
        distance from the camera.</para>

        <para>Default: zero (not used)</para>
      </section>

      <section>
        <title>TargetHeight</title>

        <para>The target height of the subject (in inches or centimeters as
        defined in the <varname>GridFile</varname>).</para>

        <para>Default: zero (not used)</para>
      </section>
    </section>

    <section xml:id="secInputControls">
      <title>Input Controls</title>

      <section>
        <title>BeginDateTime</title>

        <para>Specify the earliest files of interest (by last modified time)
        in an input hot directory using ISO 8601 extended format:
        YYYY-MM-DDTHH:MM:SS</para>

        <para>Special value: blank (or anything invalid) disables</para>

        <para>Default: blank</para>
      </section>

      <section>
        <title>DeleteAfter</title>

        <para>If true, files are deleted from the "hot directory" input as
        they are ingested into the SDK.</para>

        <para>Default: false</para>

        <warning>
          <para>Use this very, very carefully. If you pause while an image is
          in the input cache, these images will be lost forever.</para>
        </warning>
      </section>

      <section>
        <title>EndDateTime</title>

        <para>Specify the latest files (by last modified time) of interest in
        an input hot directory using ISO 8601 extended format:
        YYYY-MM-DDTHH:MM:SS</para>

        <para>Special value: blank (or anything invalid) disables</para>

        <para>Default: blank</para>
      </section>

      <section>
        <title>Format</title>

        <para>Specifies the image encoding format that the data from an IP
        camera. This is useful if the URL suffix doesn't match the data
        format. For example,
        <uri>http://root:wireless@192.168.1.228/axis-cgi/jpg/image.cgi</uri>
        returns JPG format data.</para>

        <note>
          <para>This value is semi-volatile. It is only read at the time a new
          HTTP-scheme Input/URL.</para>
        </note>

        <para>Special value: blank reverts to the suffix of the
        <varname>URL</varname>.</para>

        <para>Default: blank</para>

        <para>Added: Version 1.68</para>
      </section>

      <section>
        <title>Loop</title>

        <para>If true, causes the input directory to be restarted from the
        beginning when all images in the directory have been processed. This
        is useful for demonstration or testing purposes.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>MaxCache</title>

        <para>The SDK caches a few images from either the IP camera or the hot
        directory so that it doesn't have to wait for an image to be acquired
        when it is ready to process the next image. This value controls the
        maximum number of frames that are cached. Smaller values will reduce
        perceived latency.</para>

        <para>Special value: Zero translates to five.</para>

        <para>Default: Zero</para>
      </section>

      <section>
        <title>MoveAfter</title>

        <para>Specifies where image files will be moved after the frame has
        been ingested into the SDK.</para>

        <para>Special value: Blank, no action</para>

        <para>Default: Blank</para>
      </section>

      <section>
        <title>NewestOnly</title>

        <para>If true only the most recently arrived file is retrieved from
        the input directory when the SDK is ready to cache another
        frame.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>NewOnly</title>

        <para>If true only images that arrive in the hot directory after the
        Input/URL is changed are used.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>NumFiles</title>

        <para>Output only value. Upon a change of Input/URL that results in a
        hot directory, this value specifies the number of files in the hot
        directory at the time of the change.</para>
      </section>

      <section>
        <title>Pause</title>

        <para>Specifies whether acquisition of frames from the input URL is
        paused or not. Be sure to heed the <link
        linkend="warnInputPause">warning above</link>. Also note that when
        pause occurs (transition from false to true), all input frames in the
        cache are dropped. The frame and faces currently being processed will
        continue to be output.</para>

        <para>Default: false (not paused)</para>
      </section>

      <section>
        <title>RestartSecs</title>

        <para>Number of seconds to wait without receiving HTTP frames before
        restarting HTTP connection.</para>

        <para>Special value: 0 (no restart)</para>

        <para>Default: 3</para>

        <para><warning>
            <para>Removed: v1.69</para>
          </warning></para>
      </section>

      <section>
        <title>SampleMsec</title>

        <para>Specifies the number of milliseconds that the SDK will wait
        between taking samples from the IP camera or the hot directory.</para>

        <para>Special value: Zero for one second</para>

        <para>Default: Zero</para>
      </section>

      <section>
        <title>Skip</title>

        <para>Specifies the number of files to be skipped for each file
        processed from an input hot directory.</para>

        <para>Default: 0 (no skipping)</para>
      </section>

      <section>
        <title>SourceId</title>

        <para>Specified an identifier for an IP camera. It is prepended to a
        time stamp for the ImageId.</para>

        <para>Default: blank (none)</para>
      </section>

      <section>
        <title>URL</title>

        <para>/Image/URL controls the input to the IfSearch console for "hot
        directory" input or live retrieval from an IP camera. See the <link
        linkend="secImageInput">Image Input section</link> above for
        details.</para>

        <para>Default: none (will not function)</para>
      </section>
    </section>

    <section>
      <title>Mark Controls</title>

      <section>
        <title>BodyColor</title>

        <para>Marks the body below a detected face that meets
        <varname>Generate/MinConsistency</varname>.</para>

        <para>Default: magenta</para>
      </section>
    </section>

    <section xml:id="secMatchControls">
      <title>Match Controls</title>

      <section>
        <title>AppendPersonId</title>

        <para>If true, if a face in the source image meets "red box"
        conditions, then =M999-PersonId is appended to the SearchId when
        writing to <varname>FaceDir</varname> or
        <varname>FaceCacheDir</varname>, where 999 is the match
        confidence.</para>

        <note>
          <para>Was briefly (between v1.68C and v1.68E) =C999-PersonId.</para>
        </note>

        <para>Default: false</para>

        <para>Added: v1.68C</para>
      </section>

      <section>
        <title>DuplicateThreshold</title>

        <para>RESERVED for future use.</para>

        <para>Default: 6</para>
      </section>

      <section>
        <title>Enable</title>

        <para>If true, casual matching is enabled allowing Image, Match, and
        XML output, and "red box" mode for the Marked image.</para>

        <para>Default: false (disabled)</para>
      </section>

      <section>
        <title>MarkConfidence</title>

        <para>Overrides <varname>MinConfidence</varname> for
        <varname>Output/MarkMatchColor</varname>.</para>

        <para>Default: zero (use <varname>MinConfidence</varname>)</para>
      </section>

      <section>
        <title>MarkMaxPersons</title>

        <para>Used for <varname>Output/MarkMatchColor</varname>; not
        considered a match if specified number of people are over
        <varname>MarkConfidence</varname>.</para>

        <para>Default: zero (no check)</para>
      </section>

      <section>
        <title>MaxDistance</title>

        <para>Override MinConfidence with the Euclidean distance between
        vectors to be considered a match.</para>

        <para>Default: 0 (no override)</para>
      </section>

      <section>
        <title>MaxFaces</title>

        <para>If <varname>PersonMode=true</varname>, the maximum number of
        total faces to be returned from the matcher before PersonMode
        combining.</para>

        <para>Default: 0 (no limit)</para>
      </section>

      <section>
        <title>MaxPersonFaces</title>

        <para>If <varname>PersonMode=true</varname>, the maximum number of
        faces for an enrolled person that will be combined in the final
        results.</para>

        <para>Default: 5</para>
      </section>

      <section>
        <title>MaxResults</title>

        <para>The maximum number of results to return from the matching
        process.</para>

        <para>Default: 0</para>
      </section>

      <section>
        <title>MinConfidence</title>

        <para>The minimum "confidence" value, in the range from 1 to 999, that
        will be returned as a possible match.</para>

        <para><figure>
            <title>Without MinConfidence</title>

            <mediaobject>
              <imageobject>
                <imagedata fileref="art/D20090324-T170221562-X0310Y0151C652E051-before.JPG"
                           scalefit="1" width="4in"></imagedata>
              </imageobject>
            </mediaobject>
          </figure><figure>
            <title>With MinConfidence=650</title>

            <mediaobject>
              <imageobject>
                <imagedata fileref="art/D20090324-T170221562-X0310Y0151C652E051-MinConf650.JPG"
                           scalefit="1" width="4in"></imagedata>
              </imageobject>
            </mediaobject>
          </figure></para>

        <para>Default: 0</para>
      </section>

      <section>
        <title>MinDistance</title>

        <para>The minimum Euclidean distance allow from the matching
        process.</para>

        <para>Default: 0 (no limit)</para>
      </section>

      <section>
        <title>PersonMethod</title>

        <para>RESERVED for future use.</para>

        <para>Default: 0</para>
      </section>

      <section>
        <title>PersonMode</title>

        <para>If true, up to <varname>MaxPersonFaces</varname> results will be
        combined in the match results. Otherwise, each enrolled face is
        considered independent.</para>

        <para>Default: true</para>
      </section>
    </section>

    <section>
      <title>Options Controls</title>

      <section>
        <title>Message</title>

        <para>Receives warning, error, and fatal messages from the SDK. They
        are formatted with a "W", "E", or "F" followed by an 8 character
        hexadecimal error code (or zeros) then the time of the message and the
        message text itself. The OEM application can clear this message to
        receive the next message. The next message is set after one minute if
        the previous message is not cleared. Fatal messages are moved to the
        front of the queue.</para>
      </section>

      <section>
        <title>NoPrompt</title>

        <para>If true, IfSearch does NOT prompt for a key to continue before
        closing itself.</para>

        <para>Default: true (NO prompt)</para>

        <warning>
          <para><emphasis>NOT volatile</emphasis>; must be specified on the
          command line or set in the registry before starting
          IfSearch.exe.</para>
        </warning>
      </section>

      <section>
        <title>PollCount</title>

        <para><emphasis>Output only</emphasis>: Zero during initialization,
        one at application startup, incremented each time options are
        scanned.</para>
      </section>

      <section>
        <title>Shutdown</title>

        <para>Set to true to command IfSearch.exe to close itself. This is the
        preferred way to shutdown the console application. In order to prevent
        multiple instances of IfSearch to be running against the same base
        registry key, IfSearch sets this true during initialization then false
        while running. A calling application should set this to true before it
        closes itself. See <link linkend="secMultipleInstances">Multiple
        Instances</link> below.</para>
      </section>

      <section>
        <title>UpdateMsec</title>

        <para>Default: zero (no check for volatile updates)</para>
      </section>
    </section>

    <section>
      <title>Output Controls for Directories</title>

      <para>Output data consists of capture images, frame images, detection
      images, cropped face images, normalized face images, and XML data files.
      The following table describes the various output categories. The output
      files are distributed to a set of directories specified in the
      configuration.</para>

      <table>
        <title>Output Files</title>

        <tgroup cols="4">
          <thead>
            <row>
              <entry align="center">Name</entry>

              <entry align="center">Data</entry>

              <entry align="center">Markings</entry>

              <entry align="center">Description</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>Capture</entry>

              <entry>Capture</entry>

              <entry>none</entry>

              <entry>Raw captured image</entry>
            </row>

            <row>
              <entry>Capture2</entry>

              <entry>Frame</entry>

              <entry>none</entry>

              <entry>Preprocessed image</entry>
            </row>

            <row>
              <entry>Marked</entry>

              <entry>Frame</entry>

              <entry>head, eyes, body</entry>

              <entry>Marked input frame</entry>
            </row>

            <row>
              <entry>NoFace</entry>

              <entry>Capture</entry>

              <entry>none</entry>

              <entry>No faces detected</entry>
            </row>

            <row>
              <entry>NoEyes</entry>

              <entry>Crop</entry>

              <entry>none</entry>

              <entry>Potential face detected, but no eyes</entry>
            </row>

            <row>
              <entry>BadFace</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Eyes detected, but low template consistency</entry>
            </row>

            <row>
              <entry>Face</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Face and eyes detected. If casual match enabled, also
              meets match criteria</entry>
            </row>

            <row>
              <entry>NoMatch</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Good face, but doesn't meet match criteria</entry>
            </row>

            <row>
              <entry>XML</entry>

              <entry>XML</entry>

              <entry>n/a</entry>

              <entry>Data of frame, faces, analytics, matches</entry>
            </row>

            <row>
              <entry>FaceCache</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Faces with directory contents managed by SDK</entry>
            </row>

            <row>
              <entry>Height</entry>

              <entry>Detect</entry>

              <entry>head</entry>

              <entry>Meets height estimate criteria</entry>
            </row>

            <row>
              <entry>Clothes</entry>

              <entry>Detect</entry>

              <entry>head</entry>

              <entry>Meets clothes color criteria</entry>
            </row>

            <row>
              <entry>NoClothes</entry>

              <entry>Detect</entry>

              <entry>head</entry>

              <entry>Does not meet clothes color criteria</entry>
            </row>

            <row>
              <entry>SkinColor</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Meets that skin tone criteria</entry>
            </row>

            <row>
              <entry>Resolved</entry>

              <entry>Detect</entry>

              <entry>head</entry>

              <entry>Meets resolver criteria</entry>
            </row>

            <row>
              <entry>ResolvedFace</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Meets resolver criteria</entry>
            </row>

            <row>
              <entry>Match</entry>

              <entry>Norm</entry>

              <entry>none</entry>

              <entry>Matching faces from INDIbase enrollment</entry>
            </row>

            <row>
              <entry>Body</entry>

              <entry>other</entry>

              <entry>none</entry>

              <entry>Body below the detected face</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Normalized face image files written to the Face, FaceCache, and
      MarkedFace directories have INDIface templates embedded into them. They
      are suitable to be transferred to Search or Enroll command mode input
      directories. Search and Retrieve command mode output directories receive
      normalized face image files from the INDIbase.</para>

      <table>
        <title>Diagnostic Files</title>

        <tgroup cols="4">
          <thead>
            <row>
              <entry align="center">Name</entry>

              <entry align="center">Data</entry>

              <entry align="center">Markings</entry>

              <entry align="center">Description</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>MarkedFace</entry>

              <entry>Norm</entry>

              <entry>eyes, skin</entry>

              <entry>Face with eyes and skin tone detection markings</entry>
            </row>

            <row>
              <entry>Recon</entry>

              <entry>other</entry>

              <entry>eyes</entry>

              <entry>A reconstruction image from a generated template</entry>
            </row>

            <row>
              <entry>Vector</entry>

              <entry>other</entry>

              <entry>n/a</entry>

              <entry>A graph representing a generated template</entry>
            </row>

            <row>
              <entry>Detect</entry>

              <entry>Frame</entry>

              <entry>heads, detectors</entry>

              <entry>Image used to detect faces</entry>
            </row>

            <row>
              <entry>Generate</entry>

              <entry>Crop</entry>

              <entry>eyes, detectors</entry>

              <entry>Image used to generate template</entry>
            </row>

            <row>
              <entry>Skin</entry>

              <entry>Frame</entry>

              <entry>none</entry>

              <entry>Input image with non-skin areas masked</entry>
            </row>

            <row>
              <entry>Charcol</entry>

              <entry>Frame</entry>

              <entry>none</entry>

              <entry>Input image converted to characteristic colors for
              clothes color matching</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Frame images and XML data files are identified by an Image ID. For
      frames captured from IP cameras, the image ID consists of a date stamp
      to the thousands of the second optionally prepended with a specified
      Camera ID. For images read from a directory, the image ID is the
      complete base name of the file. Cropped and normalized face image files
      are identified by a Face ID. The face ID consists of the image ID
      appended with the x,y coordinates of the position of the face in the
      original image and the quality and consistency values for the detected
      face.</para>

      <para>Nomenclature for SDK Output File Names:</para>

      <variablelist>
        <varlistentry>
          <term>X1234Y0567</term>

          <listitem>
            <para>The center of the face was detected at pixel x,y coordinates
            (1234,0567)</para>

            <note>
              <para>Pixel coordinates are grow to the left and down.</para>
            </note>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>W194</term>

          <listitem>
            <para>The detected face was 194 pixels wide.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Q789</term>

          <listitem>
            <para>The face was detected at 78.9% "quality"</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>C543</term>

          <listitem>
            <para>A face template with 54.3% "consistency" was
            generated</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>E092</term>

          <listitem>
            <para>Eyes located 92 pixels apart were used to generate the
            template</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>R03</term>

          <listitem>
            <para>This person or face was ranked 3rd in a search or casual
            match.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>M890</term>

          <listitem>
            <para>This person or face has a 89.0% "match confidence"</para>
          </listitem>
        </varlistentry>
      </variablelist>

      <para>Capture image file format is controlled by
      <varname>Input/Format</varname>. Face, FaceCache, MarkedFace, Generate,
      and ResolveFace images are controlled by
      <varname>Output/FaceFormat</varname> and
      <varname>Output/FaceQuality</varname>. All other image files are
      controlled by <varname>Output/Format</varname> and
      <varname>Output/Quality</varname>.</para>

      <para>Except for BaseDir all the controls below default to empty (i.e.
      no output for that class of file). See <link
      linkend="secSpecifyingOutputDirectories">Specifying Directories</link>
      above for details relating to these output directories as well as input
      or output directories in other sections.</para>

      <section>
        <title>BadFaceDir</title>

        <para>Faces where eyes were detected, but didn't meet
        <varname>Generate/MinConsistency</varname>.</para>
      </section>

      <section>
        <title>BaseDir</title>

        <para>This can be used as a base directory for the other input and
        output directories if they are relative. See <link
        linkend="secSpecifyingOutputDirectories">Specifying Directories</link>
        above for details.</para>

        <para>Default: <filename>../Output</filename></para>
      </section>

      <section>
        <title>BodyDir</title>

        <para>Outputs an image containing the detected head and a rectangle
        below the head where a body would be expected.</para>
      </section>

      <section>
        <title>Capture2Dir</title>

        <para>The input image for face detection after preprocessing.</para>

        <note>
          <para>Files written to this directory are in
          <varname>Output/Format</varname>.</para>
        </note>

        <warning>
          <para>This will change to Output/InputDir in the future.</para>
        </warning>
      </section>

      <section>
        <title>CaptureDir</title>

        <para>A copy of the raw original (before preprocessing) image from
        camera or file.</para>

        <note>
          <para>Files written to this directory are in
          <varname>Input/Format</varname>.</para>
        </note>
      </section>

      <section>
        <title>ClothesDir</title>

        <para>A frame image with the face marked that met the criteria for a
        clothes color match. See the <link linkend="secClothesColor">Clothes
        Color Controls</link> section.</para>
      </section>

      <section>
        <title>FaceCacheDir</title>

        <para>Faces that have been detected and templates generated (if
        <varname>Generate/Enable=true</varname>) and are matched to the
        INDIbase (if <varname>Match/Enable=true</varname>) are placed here in
        addition to FaceDir. The SDK manages this directory and periodically
        scans this directory and deletes the oldest files to bring the number
        of files in the cache directory down to
        <varname>Output/MaxCache</varname>.</para>

        <para>Change: v1.69E - Faces written to the
        <varname>NoMatchDir</varname> are also cached here.</para>
      </section>

      <section>
        <title>FaceDir</title>

        <para>Faces that have been detected and templates generated (if
        <varname>Generate/Enable=true</varname>) and are matched to the
        INDIbase (if <varname>Match/Enable=true</varname>) are placed
        here.</para>
      </section>

      <section>
        <title>HeightDir</title>

        <para>A frame image with the face marked that met the criteria for
        height estimation match. See the <link
        linkend="secHeightControls">Height Controls</link> section
        above.</para>
      </section>

      <section>
        <title>ImageDir</title>

        <para>When casual matching is in effect
        (<varname>Match/Enable=true</varname>) a composite image with the
        detected face at the center surrounded by up to twelve closest
        matching enrolled faces is written here.</para>
      </section>

      <section>
        <title>MatchDir</title>

        <para>The enrolled face image files are written to this directory for
        matches that meet the criteria set in the <link
        linkend="secMatchControls">Match Controls</link> section. The file
        name is the format {ImageId}-X0123Y0456C678E099-R01.ext where
        (123,456) are the x,y coordinates of the center of the detected face,
        678 is the template consistency, 99 is the number of pixels between
        the eyes, and the rank of the match is 1.</para>
      </section>

      <section>
        <title>MarkedDir</title>

        <para>The input frame with various items detected marked. See <link
        linkend="secOutputMark">Output Controls for Marking Images</link>
        below for what can be marked.</para>
      </section>

      <section>
        <title>MarkedFaceDir</title>

        <para>Faces that have been detected and templates generated (if
        <varname>Generate/Enable=true</varname>) and are matched to the
        INDIbase (if <varname>Match/Enable=true</varname>) are placed here
        with the eye locations marked and, if Face Color detection is enabled,
        the sampled skin areas are marked.</para>
      </section>

      <section>
        <title>NoClothesDir</title>

        <para>Destination of face-marked images in which clothes matching
        <emphasis>didn't</emphasis> detect a match.</para>

        <para>Added: v1.68</para>
      </section>

      <section>
        <title>NoEyesDir</title>

        <para>Faces where we were unable to detect eyes are placed
        here.</para>
      </section>

      <section>
        <title>NoFaceDir</title>

        <para>Frames where no faces were detected are placed here.</para>
      </section>

      <section>
        <title>NoMatchDir</title>

        <para>When casual matching is enabled, faces where good templates were
        generated, but did not meet the criteria set in the <link
        linkend="secMatchControls">Match Controls</link> section are written
        here.</para>

        <para>Change: v1.69E - Faces that written to this directory are also
        cached in <varname>FaceCacheDir</varname>.</para>
      </section>

      <section>
        <title>ReconDir</title>

        <para>Diagnostic reconstruction images of generated face templates are
        written to this directory. See <link
        linkend="figReconstruction">Reconstruction figure</link>.</para>
      </section>

      <section>
        <title>VectorDir</title>

        <para>Diagnostic vector graph images of generated face templates are
        written to this directory. See <link linkend="figVector">Vector
        figure</link>.</para>
      </section>

      <section>
        <title>XMLDir</title>

        <para>An XML file is written to this directory describing the frame,
        faces found, and matches is written to this directory.</para>

        <warning>
          <para>The XML format is likely to change. Please contact EIRC before
          using these files.</para>
        </warning>
      </section>
    </section>

    <section xml:id="secOutputMark">
      <title>Output Controls for Marking Images</title>

      <para>Most of these controls are for setting colors for
      <varname>Output/MarkedDir</varname> images. See <link
      linkend="secSpecifyingColors">Setting Colors</link>. If a control is
      missing it's default is used; if a control is present, but blank, that
      mark is disabled.</para>

      <section>
        <title>MarkAllColor</title>

        <para>Marks all detectors in the Detect image.</para>

        <para>Default: none</para>
      </section>

      <section>
        <title>MarkBackgroundColor</title>

        <para>Sets the background color for the Marked image.</para>

        <para>Default: none</para>
      </section>

      <section>
        <title>MarkBackgroundFile</title>

        <para>Sets a file to be used instead of the input frame for the Marked
        image.</para>

        <para>Default: empty</para>
      </section>

      <section>
        <title>MarkBackgroundTransparency</title>

        <para>Sets the transparency of the background color.</para>

        <para>Default: 100</para>
      </section>

      <section>
        <title>MarkBadFaceColor</title>

        <para>Marks faces where eyes were detected but were less than
        Generate/MinConsistency.</para>

        <para>Default: green</para>
      </section>

      <section>
        <title>MarkClothes</title>

        <para>If true, characteristic colors are shown where clothes color
        detection is taking place.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>MarkEyeColor</title>

        <para>Marks the eye location for generated templates.</para>

        <para>Default: yellow</para>
      </section>

      <section>
        <title>MarkEyeRoiColor</title>

        <para>Marks the eye region of interest and indicators of the eye
        detector sizes in the Generate image.</para>

        <para>Default: none</para>
      </section>

      <section>
        <title>MarkFaceColor</title>

        <para>Marks the location of a detected face when
        Generate/MinConsistency is met.</para>

        <para>Default: yellow</para>
      </section>

      <section>
        <title>MarkMatchColor</title>

        <para>Marks the location of a detected face when it has found a match
        in the INDIbase. See also the <varname>MarkMinConfidence</varname> and
        <varname>MarkMaxPersons</varname> in <link
        linkend="secMatchControls">Match Controls</link>.</para>

        <para>Default: red (hence the name "Red Box" mode)</para>

        <figure>
          <title>Marking MarkMatchColor</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="art/26-.999000.JPG"></imagedata>
            </imageobject>
          </mediaobject>
        </figure>
      </section>

      <section>
        <title>MarkNoEyesColor</title>

        <para>Marks detected potential faces where no eyes were
        detected.</para>

        <para>Default: blue</para>
      </section>

      <section>
        <title>MarkOverCrop</title>

        <para>The amount outside of the detected face that is written over the
        background of the Marked image.</para>

        <para>Default: 133</para>
      </section>
    </section>

    <section>
      <title>Output Controls for Other Purposes</title>

      <section>
        <title>FaceFormat</title>

        <para>Sets the image file format for Face, FaceCache, MarkedFace,
        Generate, and ResolveFace images.</para>

        <para>Default: PNG</para>
      </section>

      <section>
        <title>FaceQuality</title>

        <para>Sets the compression quality level for Face, FaceCache,
        MarkedFace, Generate, and ResolveFace image files. Ranges from 0 for
        highly compressed files to 100 for uncompressed files.</para>

        <para>Special value: -1, let the compressor decide.</para>

        <para>Default: -1</para>
      </section>

      <section>
        <title>FacesProcessed</title>

        <para>Output only. Shows the number of faces processed.</para>
      </section>

      <section>
        <title>Format</title>

        <para>Sets the image file format for non-face images.</para>

        <para>Default: JPG</para>
      </section>

      <section>
        <title>ForceMarked</title>

        <para>Forces a marked image to be output even if there are no
        markings. This is used to make sure a marked image is written for
        every input frame even if no faces are found.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>FramesProcessed</title>

        <para>Output only. Shows the number of frames processed.</para>
      </section>

      <section>
        <title>LogDetail</title>

        <para>Specifies the minimum level of detail written to the log file.
        Levels are Leave (log everything), Enter (log function entry), Detail
        (detailed data), Debug (debugging information), Info (informational
        messages), Progress (progress messages), Warning (only warnings or
        worse), Error (only severe errors or worse), Fatal (only error that
        shutdown the console).</para>

        <para>Default: Info</para>
      </section>

      <section>
        <title>LogFile</title>

        <para>Special value: "none" for no log file</para>

        <para>Default: <filename>./log/IfSearch-@.log</filename> relative to
        <varname>Output/BaseDir</varname></para>
      </section>

      <section>
        <title>LogStdout</title>

        <para>If true also logs to stdout of the console at Info level.</para>

        <para>Default: true</para>
      </section>

      <section>
        <title>MaxCache</title>

        <para>The target number of files to maintain in the
        <varname>Output/FileCacheDir</varname>.</para>

        <para>Default: 64</para>
      </section>

      <section>
        <title>Quality</title>

        <para>Sets the compression quality level for non-face image files.
        Ranges from 0 for highly compressed files to 100 for uncompressed
        files.</para>

        <para>Special value: -1, let the compressor decide.</para>

        <para>Default: -1</para>
      </section>

      <section>
        <title>WriteFaceInfo</title>

        <para>If true, generated templates are embedded in face image files.
        Requires <varname>Output/FaceFormat=PNG</varname>.</para>

        <para>Default: true</para>
      </section>
    </section>

    <section>
      <title>PreProcess Controls</title>

      <para>As more preprocessing controls are exposed (skin tone detection,
      low variance detection, luminance stretching, etc) they will complete
      this section.</para>

      <section>
        <title>Aspect</title>

        <para>Specify the adjustment of the ratio of the vertical scale to the
        horizontal scale.</para>

        <para>Special value: 0.0 converts to 1.0 (no change)</para>

        <para>Default: 0.0 (no change)</para>
      </section>

      <section>
        <title>Rotate</title>

        <para>Specify the number of degrees the input image is to be rotated
        counter-clockwise.</para>

        <para>Special value: 0.0 converts to 1.0 (no change)</para>

        <para>Default: 0.0 (no change).</para>
      </section>

      <section>
        <title>Scale</title>

        <para>Specify a scale factor for the input image.</para>

        <para>Special value: 0.0 converts to 1.0 (no change).</para>

        <para>Default: 1.0 (no change).</para>
      </section>
    </section>

    <section>
      <title>Resolve Controls</title>

      <para>The "Resolver" takes confidence levels from all steps of the
      facial analytics and combines the results to get an overall confidence
      level. If this overall level falls between the specified
      <varname>MinConfidence</varname> and <varname>MaxConfidence</varname>,
      then that frame marking the detected face and/or the face image will be
      written to output directories. Each factor (<varname>Quality</varname>,
      <varname>Consistency</varname>, <varname>FaceColor</varname>,
      <varname>Height</varname>, <varname>LowerClothes</varname>, and
      <varname>UpperClothes</varname>) can be weighted (even negatively) in
      the overall value.</para>

      <section>
        <title>Consistency</title>

        <para>The weight given to generated template consistency.</para>

        <para>Default: zero (not included)</para>
      </section>

      <section>
        <title>Enable</title>

        <para>Must be true for operation of the Resolver.</para>

        <para>Default: false</para>
      </section>

      <section>
        <title>FaceColor</title>

        <para>The weight given to the confidence of the closest matching face
        color key.</para>

        <para>Default: zero (not included)</para>
      </section>

      <section>
        <title>FaceDir</title>

        <para>The output directory for resolved faces.</para>

        <para>Default: blank (no face output)</para>
      </section>

      <section>
        <title>Height</title>

        <para>The weight given to height estimation confidence.</para>

        <para>Default: zero (not included)</para>
      </section>

      <section>
        <title>LowerClothes</title>

        <para>The weight given to lower clothes color match.</para>

        <para>Default: zero (not included)</para>
      </section>

      <section>
        <title>MarkedDir</title>

        <para>The output directory for frames with the resolved face
        marked.</para>

        <para>Default: blank (no frame output)</para>
      </section>

      <section>
        <title>MaxConfidence</title>

        <para>The maximum overall confidence level to be consider
        resolved.</para>

        <para>Default: zero (no maximum)</para>
      </section>

      <section>
        <title>MinConfidence</title>

        <para>The minimum overall confidence level to be considered
        resolved.</para>

        <para>Default: zero (no minimum)</para>
      </section>

      <section>
        <title>Quality</title>

        <para>The weight given to face detection quality.</para>

        <para>Default: zero (not included)</para>
      </section>

      <section>
        <title>UpperClothes</title>

        <para>The weight given to upper clothes color match.</para>

        <para>Default: zero (not included)</para>
      </section>
    </section>
  </chapter>

  <chapter>
    <title>Command Mode Reference</title>

    <para>IfSearch can be commanded to perform other actions in Search,
    Enroll, and Retrieve modes.</para>

    <para><variablelist>
        <varlistentry>
          <term>Search Mode</term>

          <listitem>
            <para>Search, VerifyList (future), Verify</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Enroll Mode</term>

          <listitem>
            <para>Enroll, Delete, Remove, RemoveAll, Rename</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Retrieve</term>

          <listitem>
            <para>Retrieve, Status, PersonReport, Enumerate (future)</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <section>
      <title>General Command Process</title>

      <para>As you can see in the <link
      linkend="chapGettingStarted-Enrolling">Enrolling</link> subsection of
      <link linkend="chapGettingStarted">Getting Started</link> above, using
      INDIface command modes follows a predictable sequence.</para>

      <orderedlist>
        <listitem>
          <para>First you set any parameters that might be needed for the
          command you plan to use.</para>
        </listitem>

        <listitem>
          <para>Second you set the name of the command in the
          <varname>Command</varname> variable. When the command is recognized,
          the <varname>Results</varname> and <varname>Reason</varname>
          variables are cleared and the command begins to execute. You can
          monitor the progress of the command via the Status variable.</para>
        </listitem>

        <listitem>
          <para>Finally, when execution of the command is complete, the
          <varname>Status</varname> variable is set to "Done" or "Error" (or
          "NotFound" for Retrieve Mode) and the <varname>Command</varname>
          variable is cleared. You can inspect the <varname>Reason</varname>
          variable for the cause of an Error status or the
          <varname>Results</varname> variable for a Done status. Note that
          "Done" is not written to the Status variable until all files have
          been written to an <varname>OutputDir</varname>.</para>
        </listitem>
      </orderedlist>

      <para><note>
          <para>While it is not required, if possible it is suggested to pause
          (<varname>Input/Pause=true</varname>) mainline processing during
          while Command Mode commands are executing achieve more predictable
          timings of command execution. Command Mode processes are at a
          slightly lower priority than mainline processes.</para>
        </note><warning>
          <para>The registry must be volatile for Command Mode to work. Set
          <varname>Options/UpdateMsec</varname> to reflect how responsive you
          want the mainline SDK process to be to command triggers.</para>
        </warning></para>

      <section xml:id="secCommonCommandVariables">
        <title>Common Variables</title>

        <para>These variables are common to all three modes.</para>

        <section>
          <title>Command</title>

          <para>The OEM application sets <varname>Command</varname> to one of
          the specified commands to trigger its execution. The SDK clears it
          after the command has finished. Invalid commands are ignored.</para>

          <warning>
            <para>Any necessary command parameters should be changed before
            setting <varname>Command</varname>.</para>
          </warning>
        </section>

        <section>
          <title>Status</title>

          <para>The SDK updates this variable as execution proceeds. The final
          status will always be "Done" "Error" or "NotFound"</para>
        </section>

        <section>
          <title>Results</title>

          <para>When <varname>Status=Done</varname>, this variable contains
          the result of command execution.</para>
        </section>

        <section>
          <title>Reason</title>

          <para>When <varname>Status=Error</varname>, this variable contains
          an explanation of the error condition.</para>
        </section>
      </section>
    </section>

    <section>
      <title>Search Mode</title>

      <para>Search Mode is used to search the INDIbase enrolled faces against
      one or more gathered faces. The faces for searching are faces that had
      been detected and templates generated (basically the output of the
      <varname>FaceDir</varname>, <varname>FaceCacheDir</varname>,
      <varname>NoMatchDir</varname>, or <varname>MarkedFaceDir</varname> with
      <varname>Output/WriteFaceInfo=true</varname>). They can be searched
      against a single person (Verify command), all of the active faces
      enrolled in the INDIbase (Search command), or, in the future, a short
      list of persons of interest (VerifyList command).</para>

      <note>
        <para>See the <link linkend="chapGettingStarted-Search">Formal
        Search</link> subsection of <link linkend="chapGettingStarted">Getting
        Started</link> above for an example.</para>
      </note>

      <para>Results: The Results variable will be set in the following format
      with <varname>Output/Delimiter</varname> between each line:</para>

      <programlisting>D20090119-T200050562-X0169Y0244C583E087.PNG search image Active
D20090119-T200109578-X0234Y0192C573E044.PNG search image Active
D20090119-T200114562-X0269Y0189C623E034.PNG search image Active
D20090119-T200115609-X0386Y0184C680E046.PNG search image Active
D20090119-T200441593-X0284Y0258C506E126.PNG search image Active
10 results
 1. 793   316057 Hume,Brit
 2. 793   970578 Biden,Joe
 3. 789    98797 Obama,Barak
 4. 773   707299 Baer,Brett
 5. 728   126628 Williams,Juan
 6. 710    59290 Obama,Michelle
 7. 682   305166 Smith,Sheppard
 8. 642   657519 Reid,Harry
 9. 593   837859 Guilianni,Rudy
10. 548   170123 GeicoGuy</programlisting>

      <para>First, each face image files will be listed with "Active" listed
      if it contains a valid embedded template. Second, a line will show the
      number of results to follow. Third, the rank, match confidence level (on
      a scale of 1 to 999), <varname>PersonKey</varname>, and
      <varname>PersonId</varname> of the best matches will be listed. In
      non-PersonMode searches, the results line contains face, not person,
      identifiers. For the Verify command, the files are listed followed by
      "Confidence=876".</para>

      <para>If <varname>Search/OutputDir</varname> is specified, the enrolled
      faces for the best matches are written. In non-PersonMode, one face
      image file is written for each of the best matching faces. The file name
      is formatted as R01M987-FK654321 to indicate match rank #1, match
      confidence 987 (scale of 1 to 999), and FaceKey 654321. In PersonMode, a
      directory named R01M987-{PersonId} is created for each person in order
      and the face images that contributed to the match are written to those
      directories with the same file name format as non-PersonMode.</para>

      <note>
        <para>This file/directory name nomenclature was changed in
        v1.68F.</para>
      </note>

      <section>
        <title>Commands</title>

        <para>Currently the Search and Verify commands are recognized.</para>

        <section>
          <title>Search</title>

          <subtitle>Searching the entire INDIbase</subtitle>

          <para>This command sorts the best matches of the templates in the
          Search/InputDir versus all of the faces enrolled in the INDIbase. In
          PersonMode, the MaxPersonFaces highest ranking results from the same
          person are combined to increase that person's confidence rating. The
          results can be limited by the <varname>MaxResults</varname> and
          <varname>MinConfidence</varname> parameters.</para>
        </section>

        <section>
          <title>Verify</title>

          <subtitle>Verifying the identity of a single person</subtitle>

          <para>This command compares the templates embedded in the face image
          files in Search/InputDir versus the faces enrolled for the specified
          <varname>PersonKey</varname> or <varname>PersonId</varname>. The
          <varname>MaxPersonFaces</varname> highest ranking results are
          combined and the confidence level is returned. No files are written
          for the Verify command.</para>
        </section>

        <section>
          <title>VerifyList (future)</title>

          <subtitle>Searching for a few persons of interest</subtitle>

          <para></para>
        </section>
      </section>

      <section>
        <title>Parameters</title>

        <para>In addition to the <link
        linkend="secCommonCommandVariables">common variables</link> above, the
        following combinations of parameters can be used to identify the
        person and faces to be enrolled. Search Mode also has parallel
        parameters from the <link linkend="secMatchControls">Match
        section</link> above: <varname>MaxFaces</varname>,
        <varname>MaxPersonFaces</varname>, <varname>MaxResults</varname>,
        <varname>PersonMethod</varname>, <varname>PersonMode</varname>.</para>

        <section>
          <title>InputDir</title>

          <para>Specifies where face template image files will be read for
          searching. See <link
          linkend="secSpecifyingOutputDirectories">Specifying
          Directories</link> above for additional information.</para>
        </section>

        <section>
          <title>OutputDir</title>

          <para>Specifies where search results face image files will be
          written. See <link
          linkend="secSpecifyingOutputDirectories">Specifying
          Directories</link> above for additional information. If blank, the
          <varname>Results</varname> variable will be populated, but no image
          files are written.</para>
        </section>
      </section>
    </section>

    <section>
      <title>Enroll Mode</title>

      <para>Enroll Mode allows you to add face templates to the INDIbase and
      to manage persons and faces in the INDIbase.</para>

      <section>
        <title>Commands</title>

        <para>You can use the Enroll, Delete, Remove, RemoveAll, and Rename
        commands in Enroll Mode.</para>

        <section>
          <title>Enroll</title>

          <subtitle>Add faces to the INDIbase</subtitle>

          <para>This command allows you to add faces that had been detected
          and templates generated (basically the output of the
          <varname>FaceDir</varname>, <varname>FaceCacheDir</varname>,
          <varname>NoMatchDir</varname>, or <varname>MarkedFaceDir</varname>
          with <varname>Output/WriteFaceInfo=true</varname>) to the INDIbase
          face template repository attached to the SDK instance. The complete
          base name of each file becomes the FaceId of the template.</para>

          <note>
            <para>See in the <link
            linkend="chapGettingStarted-Enrolling">Enrolling</link> subsection
            of <link linkend="chapGettingStarted">Getting Started</link> above
            for an example.</para>
          </note>

          <para>Results: The Results variable will start with either
          "<computeroutput>Unidentified Enrollment</computeroutput>" for
          non-person mode or "<computeroutput>PersonId=N7969000@CA5
          PersonKey=123456</computeroutput>" for person mode. It will be
          followed by either "<computeroutput>{FaceId} already
          enrolled</computeroutput>." or "<computeroutput>{FaceId} enrolled as
          {PersonKey}:{FaceKey} Active</computeroutput>" for each image in the
          specified <varname>InputDir</varname>.</para>

          <section>
            <title>Non-Person Mode</title>

            <para>If the <varname>PersonMode</varname> is false, then face
            templates are added to the INDIbase without identifying them as a
            particular person. The <varname>PersonKey</varname> and
            <varname>PersonId</varname> parameters are ignored.</para>
          </section>

          <section>
            <title>Person Mode</title>

            <para>You can add face templates to an existing person in the
            INDIbase by specifying either their numeric
            <varname>PersonKey</varname> (assigned by INDIbase when the person
            record was created) or their <varname>PersonId</varname>. If the
            specified <varname>PersonId</varname> is not already in the
            INDIbase, then a new person record is created.</para>
          </section>

          <section>
            <title>Anonymous Enrollment (future)</title>

            <para>With Anonymous Enrollment, the INDIbase will assign a
            PersonKey to new sets of faces that belong to an unknown person.
            They PersonId can be assigned later via the Rename command.</para>
          </section>
        </section>

        <section>
          <title>Delete</title>

          <subtitle>Delete one face from the INDIbase</subtitle>

          <para>This command allows you to delete a single face template from
          being included in searches. The face is still enrolled can be
          retrieved for future reinstatement (method TBD). Specify either the
          numeric <varname>FaceKey</varname> assigned to the face when it was
          enrolled or the <varname>FaceId</varname> (typically the complete
          base file name of the image template file at the time of
          enrollment). For <varname>FaceId</varname> lookups, a
          <varname>PersonKey</varname> must be specified also. If the face was
          enrolled in non-person mode, then specify
          <varname>PersonKey=0</varname>. For person mode enrollments either
          specify an existing <varname>PersonKey</varname> or
          <varname>PersonId</varname>.</para>
        </section>

        <section>
          <title>Remove</title>

          <subtitle>Remove all of a Person's faces from the
          INDIbase</subtitle>

          <para>Specify an existing PersonKey or PersonId.</para>
        </section>

        <section>
          <title>RemoveAll</title>

          <subtitle>Remove all faces from the INDIbase to start over
          fresh</subtitle>

          <para>Set PersonId=Confirm to confirm that you want to remove all
          faces from the INDIbase.</para>
        </section>

        <section>
          <title>Rename</title>

          <subtitle>Assign a new PersonId to an existing person</subtitle>

          <para>Specify an existing PersonKey or PersonId to be renamed and a
          NewPersonId with the new name.</para>
        </section>
      </section>

      <section>
        <title>Parameters</title>

        <para>In addition to the <link
        linkend="secCommonCommandVariables">common variables</link> above, the
        following combinations of parameters can be used to identify the
        person and faces to be enrolled.</para>

        <section>
          <title>PersonKey</title>

          <para>A unique number identifying an existing person in the
          INDIbase. INDIbase assigns this number to new person records. An
          unidentified (non-person mode) enrollment has
          <varname>PersonKey=0</varname>.</para>
        </section>

        <section>
          <title>PersonId</title>

          <para>A unique string supplied by the OEM application as its
          identifier for a person.</para>
        </section>

        <section>
          <title>FaceKey</title>

          <para>A unique number identifying an existing face enrolled in the
          INDIbase. INDIbase assigns this number at enrollment.</para>
        </section>

        <section>
          <title>FaceId</title>

          <para>A string that identifies an face enrolled in the INDIbase. The
          strings must be unique within the person record. The unidentified
          enrollments must also have unique <varname>FaceId</varname>s.</para>
        </section>

        <section>
          <title>InputDir</title>

          <para>Specifies where face template image files will be read for
          enrollment. See <link
          linkend="secSpecifyingOutputDirectories">Specifying
          Directories</link> above for additional information.</para>
        </section>

        <section>
          <title>SetDescription</title>

          <para>If non-empty during an Enroll command, the person's
          description in the INDIbase is set to this string.</para>
        </section>

        <section>
          <title>Description</title>

          <para>Returns either a newly set or existing description for the
          person from the INDIbase, if any.</para>
        </section>

        <section>
          <title>NewPersonId</title>

          <para>A string identifying the person to replace their existing
          <varname>PersonId</varname>. The <varname>NewPersonId</varname> can
          not already exist in the INDIbase.</para>
        </section>
      </section>
    </section>

    <section>
      <title>Retrieve Mode</title>

      <para>Retrieve Mode can be used to retrieve a single face enrollment or
      all the faces enrolled for a person from the INDIbase.</para>

      <section>
        <title>Commands</title>

        <para></para>

        <section>
          <title>Retrieve</title>

          <para>The Retrieve command will retrieve all of the faces enrolled
          for a person or will retrieve a single face. For a single face, you
          can specify <varname>FaceKey</varname> or person record
          identification (<varname>PersonKey</varname> or
          <varname>PersonId</varname>) and <varname>FaceId</varname>. To
          retrieve all enrolled faces for a person, specify either a
          <varname>PersonKey</varname> or <varname>PersonId</varname> with
          <varname>FaceKey</varname> blank, non existent, or zero.</para>

          <para>Results: For person retrieval, the Results variable will start
          with "<computeroutput>Person
          {PersonKey}={PersonId}</computeroutput>". For each face enrolled a
          "<computeroutput>Face: {FaceKey}={FaceId}
          {{status}}</computeroutput>" entry is appended to the results.
          Values for status are "Inconsistent" (not suitable for matching),
          "Active" (used for matching), "Deleted" (has been deleted), or
          "Error" (likely the face's XML file has been damaged).</para>
        </section>

        <section>
          <title>Status</title>

          <para>The Status command will return information about the
          enrollment to the INDIbase.</para>

          <para>Results: Four comma delimited numbers.</para>

          <orderedlist>
            <listitem>
              <para>Number of identified people enrolled</para>
            </listitem>

            <listitem>
              <para>Number of unidentified faces enrolled</para>
            </listitem>

            <listitem>
              <para>Total number of faces enrolled</para>
            </listitem>

            <listitem>
              <para>Total number of faces enrolled that are included in
              searches</para>
            </listitem>
          </orderedlist>

          <para>Added: v1.69H</para>
        </section>

        <section>
          <title>PersonReport</title>

          <para>The PersonReport command will write a comma delimited file
          with one line for each person enrolled in the INDIface. The name of
          the report file must be specified in <varname>ReportFile</varname>
          variable before setting <varname>Command=PersonReport</varname> Each
          line will contain four values.</para>

          <orderedlist>
            <listitem>
              <para>PersonKey (numeric identifier issued by INDIface when a
              new person was enrolled)</para>
            </listitem>

            <listitem>
              <para>PersonId surrounded by double quotes (string specified
              when a new person was enrolled)</para>
            </listitem>

            <listitem>
              <para>Number of faces enrolled for that person</para>
            </listitem>

            <listitem>
              <para>One if the person is active for searching or zero
              otherwise</para>
            </listitem>
          </orderedlist>

          <para>Results: "# bytes written to {ReportFile} for #
          persons".</para>

          <note>
            <para>XML format reports are anticipated in the future.</para>
          </note>
        </section>

        <section>
          <title>Enumerate (future)</title>

          <para>We will have the ability to enumerate the unidentified
          (non-person mode) enrollments and the list of person records once
          someone identifies a preferred interface.</para>
        </section>
      </section>

      <section>
        <title>Parameters</title>

        <para>In addition to the <link
        linkend="secCommonCommandVariables">common variables</link> above, the
        following combinations of parameters can be used for Retrieve
        Mode.</para>

        <section>
          <title>OutputDir</title>

          <para>Specifies where face template image files will be written. See
          <link linkend="secSpecifyingOutputDirectories">Specifying
          Directories</link> above for additional information. If blank, the
          keys and ids are enumerated in the Results variable, but no image
          files are written.</para>
        </section>

        <section>
          <title>ActiveOnly</title>

          <para>If true, only faces that are currently used for matching are
          retrieved. Otherwise all enrolled faces, active or not, are
          retrieved.</para>

          <para>Default: true</para>

          <para>Added: v1.68D</para>
        </section>

        <section>
          <title>ReportFile</title>

          <para>Name of file where PersonReport is to be written.</para>

          <para>Default: none (error if missing)</para>

          <para>Added: v1.69H</para>
        </section>
      </section>
    </section>

    <section>
      <title>Error Reasons</title>

      <para>The following messages could be returned in the
      <varname>Reason</varname> variable for Command Mode commands.</para>

      <variablelist>
        <varlistentry>
          <term>No FaceBase</term>

          <listitem>
            <para>No INDIbase face template repository was opened</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Enroll/InputDir is blank</term>

          <listitem>
            <para>No input directory was specified from which to retrieve face
            template files.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>PersonKey 123456 does not exist</term>

          <listitem>
            <para>The specified person key is not enrolled in the
            INDIbase.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>PersonId ... does not exist</term>

          <listitem>
            <para>The specified person id is not enrolled in the
            INDIbase.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>PersonId must be specified for new person</term>

          <listitem>
            <para>Currently each person must have a PersonId. This restriction
            will go away with Anonymous Enrollment.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Cannot create new person</term>

          <listitem>
            <para>Internal error</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Can't cd to {InputDir}</term>

          <listitem>
            <para>The specified InputDir likely doesn't exist.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>{InputDir} is empty</term>

          <listitem>
            <para>The specified InputDir does not contain any supported image
            files.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Null image in {filename}</term>

          <listitem>
            <para>The image file is likely corrupt.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>INDI EigenFace Null Status</term>

          <listitem>
            <para>No template data in the image file. Images for enrollment
            must come from the output of FaceDir, FaceCacheDir, or
            MarkedFaceDir with both Detect/Enable=true and
            Generate/Enable=true.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Error parsing XML ...</term>

          <listitem>
            <para>The template data embedded in the image file was somehow
            damaged or is incompatible with the SDK.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Missing INDI-EigenFace-Template</term>

          <listitem>
            <para>The template data embedded in the image file was somehow
            damaged or is incompatible with the SDK.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>FaceKey 654321 does not exist</term>

          <listitem>
            <para>The specified face id is not enrolled in the
            INDIbase.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>FaceId ... does not exist for {PersonId}</term>

          <listitem>
            <para>The specified face id is not enrolled in the INDIbase for
            the specified person.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>FaceId ... does not exist unidentified</term>

          <listitem>
            <para>The specified face id is not enrolled in the INDIbase
            without person identification.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>FaceId or FaceKey must be specified</term>

          <listitem>
            <para>For the Delete command.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Must specify person key or id to ...</term>

          <listitem>
            <para>No person key or id was specified.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>No Consistent Faces to search</term>

          <listitem>
            <para>None of the image files in Search/InputDir contained
            embedded templates.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>No ReportFile name specified</term>

          <listitem>
            <para>ReportFile name must be specified before setting
            Retrieve/Command=PersonReport</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>XML format not yet supported</term>

          <listitem>
            <para>Support for XML reports has not yet been completed.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Error opening {ReportFile} for truncated write: {Error}</term>

          <listitem>
            <para>File system error</para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
  </chapter>

  <chapter>
    <title>Changes</title>

    <para>This chapter will show plans for future changes to the SDK, the
    history of changes to the SDK, and a change log for this document
    itself.</para>

    <section>
      <title>SDK Plans</title>

      <para>Anticipated changes to the SDK will be listed here in approximate
      soonest-first order.</para>

      <section>
        <title>Short Term</title>

        <subtitle>Scheduled second quarter 2011</subtitle>

        <itemizedlist>
          <listitem>
            <para>Support for AVS Video Converter's JPE image export
            output</para>
          </listitem>

          <listitem>
            <para>Handle empty FaceBase/BaseDir</para>
          </listitem>

          <listitem>
            <para>Combine Verify results up to MaxPersonFaces</para>
          </listitem>

          <listitem>
            <para>Anonymous enrollment</para>
          </listitem>

          <listitem>
            <para>Implement PreProcess/MaxPixelRows and MaxPixelCols</para>
          </listitem>

          <listitem>
            <para>Implement Input/Crop</para>
          </listitem>

          <listitem>
            <para>Specify eye locations on Enroll</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Medium Term</title>

        <subtitle>Scheduled third quarter 2011</subtitle>

        <para>These capabilities may be implemented in SDK1 or wait for second
        generation.</para>

        <itemizedlist>
          <listitem>
            <para>Enroll batch capability for person or non-person
            enrollment</para>
          </listitem>

          <listitem>
            <para>AutoEnroll mode?</para>
          </listitem>

          <listitem>
            <para>Volatile LogFile and LogDetail</para>
          </listitem>

          <listitem>
            <para>Retrieve/Command=Enumerate once someone defines what they
            need.</para>
          </listitem>

          <listitem>
            <para>Expose color correction to SDK</para>
          </listitem>

          <listitem>
            <para>Implement ImageIdFormat, FaceIdFormat and PersonIdFormat as
            controls</para>
          </listitem>

          <listitem>
            <para>Implement binary facial recognition data files and/or embed
            data in DLL plugins</para>
          </listitem>

          <listitem>
            <para>Binary INDIbase templates</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Long Term</title>

        <para>If this becomes necessary in SDK1 it will be implemented.
        Otherwise we will use a SQL-based INDIbase in the second
        generation.</para>

        <itemizedlist>
          <listitem>
            <para>Volatile FaceBase</para>
          </listitem>
        </itemizedlist>
      </section>
    </section>

    <section>
      <title>SDK Change History</title>

      <para>This section will document changes to the SDK since January 2010 (
      v1.65) release in most recent first order.</para>

      <section>
        <title>Version 1.71</title>

        <subtitle>Scheduled for release at end of July</subtitle>

        <itemizedlist>
          <listitem>
            <para>Added Height/HeightUnits parameter and improved height
            confidence calculation</para>
          </listitem>

          <listitem>
            <para>Added Input/ImageId parameter to allow shared input
            directory with Avigilon clients to mimic behavior of a live camera
            connection</para>
          </listitem>

          <listitem>
            <para>Improved productivity with multimegapixel greyscale input
            images.</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.70</title>

        <subtitle>Released May 28, 2011</subtitle>

        <itemizedlist>
          <listitem>
            <para>Changed wording on Enroll=Delete error messages</para>
          </listitem>

          <listitem>
            <para>Object detection exceptions are fatal.</para>
          </listitem>

          <listitem>
            <para>Cosmetic changes to detect and composite images</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.69</title>

        <subtitle>Released April 25, 2011</subtitle>

        <itemizedlist>
          <listitem>
            <para>Added Interface controls for object detection</para>
          </listitem>

          <listitem>
            <para>Completely remove ResetAfter; we'll leave RestartSecs to
            cover emergencies</para>
          </listitem>

          <listitem>
            <para>Improved HTTP communication</para>
          </listitem>

          <listitem>
            <para>NoMatchDir faces are also written to FaceCacheDir</para>
          </listitem>

          <listitem>
            <para>No longer reports file written after file write error</para>
          </listitem>

          <listitem>
            <para>Fixed Input/Format to Output/Format on NoFaceDir
            files.</para>
          </listitem>

          <listitem>
            <para>Added Status and PersonReport commands to Retrieve
            Mode</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.68</title>

        <subtitle>Released March 26, 2011</subtitle>

        <itemizedlist>
          <listitem>
            <para>Added Output/NoClothes for non-matching clothes</para>
          </listitem>

          <listitem>
            <para>Added Input/Format for IP camera URLs suffix that don't
            match the image data returned.</para>
          </listitem>

          <listitem>
            <para>Improved Clothes Matching discrimination</para>
          </listitem>

          <listitem>
            <para>Added Mark/AppendPersonId</para>
          </listitem>

          <listitem>
            <para>Added Retrieve/ActiveOnly</para>
          </listitem>

          <listitem>
            <para>Changed nomenclature of Search/OuputDir file/directory
            names.</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.67</title>

        <subtitle>Released February 20, 2011</subtitle>

        <itemizedlist>
          <listitem>
            <para>Builds now for 32-bit Windows and 64-bit Linux
            (Ubuntu).</para>
          </listitem>

          <listitem>
            <para>Upgraded to v2.2.0 Intel object detection library.</para>
          </listitem>

          <listitem>
            <para>Separated use of MaxDistance from MinConfidence.
            MinDistance, MaxDistance, and DuplicateThreshold are used to
            qualify vectors initially and MinConfidence is used to limit final
            results.</para>
          </listitem>

          <listitem>
            <para>Enroll/OutputDir did nothing so it was removed.</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.66</title>

        <subtitle>Released February 5, 2011</subtitle>

        <itemizedlist>
          <listitem>
            <para>Restructured for build without DDT and IJM libraries</para>
          </listitem>

          <listitem>
            <para>Removed duplicate results of same unidentified face in
            non-person search</para>
          </listitem>

          <listitem>
            <para>Restructured initialization for running in Linux</para>
          </listitem>
        </itemizedlist>
      </section>
    </section>

    <section>
      <title>SDK Document Change Log</title>

      <para>This document was first released with SDK version 1.60 and the
      first "official" release of this document with v1.68. Changes since
      v1.68 will be listed below latest first.</para>

      <section>
        <title>Version 1.71</title>

        <itemizedlist>
          <listitem>
            <para>Updated diagrams in <link linkend="secTechNote2">Tech Note
            2</link>.</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.70</title>

        <itemizedlist>
          <listitem>
            <para>Added missing and future controls to Detect section:
            (ForceFind, GroupMethod, GroupThreshold, NeighborThreshold, and
            OverlapThreshold)</para>
          </listitem>

          <listitem>
            <para>Moved "Getting Started" to a chapter on its own.</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Version 1.69</title>

        <itemizedlist>
          <listitem>
            <para>Restored short term changes.</para>
          </listitem>

          <listitem>
            <para>Added note to Input/Format.</para>
          </listitem>

          <listitem>
            <para>Added legal notices and moved Notes to an Appendix.</para>
          </listitem>

          <listitem>
            <para>Added Tech Note: How a Frame Becomes a Match</para>
          </listitem>

          <listitem>
            <para>Added two new commands to Retrieve Mode</para>
          </listitem>

          <listitem>
            <para>Added clothes color confidence figures</para>
          </listitem>

          <listitem>
            <para>Added multiple output directory <link
            linkend="noteMultipleOutputDirs">note</link></para>
          </listitem>

          <listitem>
            <para>Added AVS4YOU to recommended tools</para>
          </listitem>
        </itemizedlist>

        <para></para>
      </section>
    </section>
  </chapter>

  <appendix>
    <title>Legal Notices</title>

    <para></para>

    <section>
      <title>Additional Terms</title>

      <para>You may have a separate written agreement with EclipseIR that
      supplements or supersedes all or portions of this License. Your use of
      some third party materials included in the SDK may be subject to other
      terms and conditions typically found in a separate license agreement or
      in the “Third Party Software Notices and/or Additional Terms and
      Conditions” found in the SDK document. Such other terms and conditions
      may require You to pass through notices to Your end users. Such other
      terms and conditions will supersede all or portions of this License in
      the event of a conflict with the terms and conditions of this
      License.</para>
    </section>

    <section>
      <title>Third Party Notices</title>

      <para>Portions of the SDK utilize or include third party libraries,
      software and other copyrighted material. Acknowledgements, licensing
      terms and disclaimers for such material are contained in the electronic
      documentation for the SDK, and Your use of such material is governed by
      their respective terms.</para>

      <orderedlist>
        <listitem>
          <para>If Developer uses the SDK to run applications developed by a
          third party or that access libraries, data, content or resources
          provided by a third party, Developer agrees that EclipseIR is not
          responsible for those libraries, applications, data, content, or
          resources. Developer understands that all libraries, data, content
          or resources which Developer may access through such third party
          libraries, applications or resources are the sole responsibility of
          the person from which they originated and that EclipseIR is not
          liable for any loss or damage that Developer may experience as a
          result of the use or access of any of those third party
          applications, data, content, or resources.</para>
        </listitem>

        <listitem>
          <para>Developer should be aware the libraries, data, content, and
          resources presented to Developer through such a third party
          application, libraries, or other resources may be protected by
          intellectual property rights which are owned by the third party (or
          by other persons or companies on their behalf). Developer may not
          modify, rent, lease, loan, sell, distribute or create derivative
          works based on these libraries, data, content, or resources (either
          in whole or in part) unless Developer have been specifically given
          permission to do so by the relevant owners or third party.</para>
        </listitem>

        <listitem>
          <para>Developer acknowledges that Developer's use of such third
          party libraries, applications, data, content, or resources may be
          subject to separate terms between Developer and the relevant third
          party. In that case, this License Agreement does not affect your
          legal relationship with these third parties.</para>
        </listitem>
      </orderedlist>

      <para>Third Party Notices and/or Additional Terms and Conditions for
      licensed 3rd party components included within all current versions of
      EclipseIR Software products. These notices and/or additional terms and
      conditions are made a part of and incorporated by reference into the
      EclipseIR Software Agreement.</para>

      <para>Licenses for LPGL 2.1, LPGL 3, and the BSD License are reproduced
      below.</para>

      <section>
        <title>LPGL v2.1</title>

        <subtitle>GNU Lesser General Public License, version 2.1</subtitle>

        <para>The SDK incorporates technologies licensed under LPGL
        v2.1</para>

        <programlisting>                  GNU LESSER GENERAL PUBLIC LICENSE
                       Version 2.1, February 1999

 Copyright (C) 1991, 1999 Free Software Foundation, Inc.
 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

[This is the first released version of the Lesser GPL.  It also counts
 as the successor of the GNU Library Public License, version 2, hence
 the version number 2.1.]

                            Preamble

  The licenses for most software are designed to take away your
freedom to share and change it.  By contrast, the GNU General Public
Licenses are intended to guarantee your freedom to share and change
free software--to make sure the software is free for all its users.

  This license, the Lesser General Public License, applies to some
specially designated software packages--typically libraries--of the
Free Software Foundation and other authors who decide to use it.  You
can use it too, but we suggest you first think carefully about whether
this license or the ordinary General Public License is the better
strategy to use in any particular case, based on the explanations below.

  When we speak of free software, we are referring to freedom of use,
not price.  Our General Public Licenses are designed to make sure that
you have the freedom to distribute copies of free software (and charge
for this service if you wish); that you receive source code or can get
it if you want it; that you can change the software and use pieces of
it in new free programs; and that you are informed that you can do
these things.

  To protect your rights, we need to make restrictions that forbid
distributors to deny you these rights or to ask you to surrender these
rights.  These restrictions translate to certain responsibilities for
you if you distribute copies of the library or if you modify it.

  For example, if you distribute copies of the library, whether gratis
or for a fee, you must give the recipients all the rights that we gave
you.  You must make sure that they, too, receive or can get the source
code.  If you link other code with the library, you must provide
complete object files to the recipients, so that they can relink them
with the library after making changes to the library and recompiling
it.  And you must show them these terms so they know their rights.

  We protect your rights with a two-step method: (1) we copyright the
library, and (2) we offer you this license, which gives you legal
permission to copy, distribute and/or modify the library.

  To protect each distributor, we want to make it very clear that
there is no warranty for the free library.  Also, if the library is
modified by someone else and passed on, the recipients should know
that what they have is not the original version, so that the original
author's reputation will not be affected by problems that might be
introduced by others.

  Finally, software patents pose a constant threat to the existence of
any free program.  We wish to make sure that a company cannot
effectively restrict the users of a free program by obtaining a
restrictive license from a patent holder.  Therefore, we insist that
any patent license obtained for a version of the library must be
consistent with the full freedom of use specified in this license.

  Most GNU software, including some libraries, is covered by the
ordinary GNU General Public License.  This license, the GNU Lesser
General Public License, applies to certain designated libraries, and
is quite different from the ordinary General Public License.  We use
this license for certain libraries in order to permit linking those
libraries into non-free programs.

  When a program is linked with a library, whether statically or using
a shared library, the combination of the two is legally speaking a
combined work, a derivative of the original library.  The ordinary
General Public License therefore permits such linking only if the
entire combination fits its criteria of freedom.  The Lesser General
Public License permits more lax criteria for linking other code with
the library.

  We call this license the "Lesser" General Public License because it
does Less to protect the user's freedom than the ordinary General
Public License.  It also provides other free software developers Less
of an advantage over competing non-free programs.  These disadvantages
are the reason we use the ordinary General Public License for many
libraries.  However, the Lesser license provides advantages in certain
special circumstances.

  For example, on rare occasions, there may be a special need to
encourage the widest possible use of a certain library, so that it becomes
a de-facto standard.  To achieve this, non-free programs must be
allowed to use the library.  A more frequent case is that a free
library does the same job as widely used non-free libraries.  In this
case, there is little to gain by limiting the free library to free
software only, so we use the Lesser General Public License.

  In other cases, permission to use a particular library in non-free
programs enables a greater number of people to use a large body of
free software.  For example, permission to use the GNU C Library in
non-free programs enables many more people to use the whole GNU
operating system, as well as its variant, the GNU/Linux operating
system.

  Although the Lesser General Public License is Less protective of the
users' freedom, it does ensure that the user of a program that is
linked with the Library has the freedom and the wherewithal to run
that program using a modified version of the Library.

  The precise terms and conditions for copying, distribution and
modification follow.  Pay close attention to the difference between a
"work based on the library" and a "work that uses the library".  The
former contains code derived from the library, whereas the latter must
be combined with the library in order to run.

                  GNU LESSER GENERAL PUBLIC LICENSE
   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION

  0. This License Agreement applies to any software library or other
program which contains a notice placed by the copyright holder or
other authorized party saying it may be distributed under the terms of
this Lesser General Public License (also called "this License").
Each licensee is addressed as "you".

  A "library" means a collection of software functions and/or data
prepared so as to be conveniently linked with application programs
(which use some of those functions and data) to form executables.

  The "Library", below, refers to any such software library or work
which has been distributed under these terms.  A "work based on the
Library" means either the Library or any derivative work under
copyright law: that is to say, a work containing the Library or a
portion of it, either verbatim or with modifications and/or translated
straightforwardly into another language.  (Hereinafter, translation is
included without limitation in the term "modification".)

  "Source code" for a work means the preferred form of the work for
making modifications to it.  For a library, complete source code means
all the source code for all modules it contains, plus any associated
interface definition files, plus the scripts used to control compilation
and installation of the library.

  Activities other than copying, distribution and modification are not
covered by this License; they are outside its scope.  The act of
running a program using the Library is not restricted, and output from
such a program is covered only if its contents constitute a work based
on the Library (independent of the use of the Library in a tool for
writing it).  Whether that is true depends on what the Library does
and what the program that uses the Library does.

  1. You may copy and distribute verbatim copies of the Library's
complete source code as you receive it, in any medium, provided that
you conspicuously and appropriately publish on each copy an
appropriate copyright notice and disclaimer of warranty; keep intact
all the notices that refer to this License and to the absence of any
warranty; and distribute a copy of this License along with the
Library.

  You may charge a fee for the physical act of transferring a copy,
and you may at your option offer warranty protection in exchange for a
fee.

  2. You may modify your copy or copies of the Library or any portion
of it, thus forming a work based on the Library, and copy and
distribute such modifications or work under the terms of Section 1
above, provided that you also meet all of these conditions:

    a) The modified work must itself be a software library.

    b) You must cause the files modified to carry prominent notices
    stating that you changed the files and the date of any change.

    c) You must cause the whole of the work to be licensed at no
    charge to all third parties under the terms of this License.

    d) If a facility in the modified Library refers to a function or a
    table of data to be supplied by an application program that uses
    the facility, other than as an argument passed when the facility
    is invoked, then you must make a good faith effort to ensure that,
    in the event an application does not supply such function or
    table, the facility still operates, and performs whatever part of
    its purpose remains meaningful.

    (For example, a function in a library to compute square roots has
    a purpose that is entirely well-defined independent of the
    application.  Therefore, Subsection 2d requires that any
    application-supplied function or table used by this function must
    be optional: if the application does not supply it, the square
    root function must still compute square roots.)

These requirements apply to the modified work as a whole.  If
identifiable sections of that work are not derived from the Library,
and can be reasonably considered independent and separate works in
themselves, then this License, and its terms, do not apply to those
sections when you distribute them as separate works.  But when you
distribute the same sections as part of a whole which is a work based
on the Library, the distribution of the whole must be on the terms of
this License, whose permissions for other licensees extend to the
entire whole, and thus to each and every part regardless of who wrote
it.

Thus, it is not the intent of this section to claim rights or contest
your rights to work written entirely by you; rather, the intent is to
exercise the right to control the distribution of derivative or
collective works based on the Library.

In addition, mere aggregation of another work not based on the Library
with the Library (or with a work based on the Library) on a volume of
a storage or distribution medium does not bring the other work under
the scope of this License.

  3. You may opt to apply the terms of the ordinary GNU General Public
License instead of this License to a given copy of the Library.  To do
this, you must alter all the notices that refer to this License, so
that they refer to the ordinary GNU General Public License, version 2,
instead of to this License.  (If a newer version than version 2 of the
ordinary GNU General Public License has appeared, then you can specify
that version instead if you wish.)  Do not make any other change in
these notices.

  Once this change is made in a given copy, it is irreversible for
that copy, so the ordinary GNU General Public License applies to all
subsequent copies and derivative works made from that copy.

  This option is useful when you wish to copy part of the code of
the Library into a program that is not a library.

  4. You may copy and distribute the Library (or a portion or
derivative of it, under Section 2) in object code or executable form
under the terms of Sections 1 and 2 above provided that you accompany
it with the complete corresponding machine-readable source code, which
must be distributed under the terms of Sections 1 and 2 above on a
medium customarily used for software interchange.

  If distribution of object code is made by offering access to copy
from a designated place, then offering equivalent access to copy the
source code from the same place satisfies the requirement to
distribute the source code, even though third parties are not
compelled to copy the source along with the object code.

  5. A program that contains no derivative of any portion of the
Library, but is designed to work with the Library by being compiled or
linked with it, is called a "work that uses the Library".  Such a
work, in isolation, is not a derivative work of the Library, and
therefore falls outside the scope of this License.

  However, linking a "work that uses the Library" with the Library
creates an executable that is a derivative of the Library (because it
contains portions of the Library), rather than a "work that uses the
library".  The executable is therefore covered by this License.
Section 6 states terms for distribution of such executables.

  When a "work that uses the Library" uses material from a header file
that is part of the Library, the object code for the work may be a
derivative work of the Library even though the source code is not.
Whether this is true is especially significant if the work can be
linked without the Library, or if the work is itself a library.  The
threshold for this to be true is not precisely defined by law.

  If such an object file uses only numerical parameters, data
structure layouts and accessors, and small macros and small inline
functions (ten lines or less in length), then the use of the object
file is unrestricted, regardless of whether it is legally a derivative
work.  (Executables containing this object code plus portions of the
Library will still fall under Section 6.)

  Otherwise, if the work is a derivative of the Library, you may
distribute the object code for the work under the terms of Section 6.
Any executables containing that work also fall under Section 6,
whether or not they are linked directly with the Library itself.

  6. As an exception to the Sections above, you may also combine or
link a "work that uses the Library" with the Library to produce a
work containing portions of the Library, and distribute that work
under terms of your choice, provided that the terms permit
modification of the work for the customer's own use and reverse
engineering for debugging such modifications.

  You must give prominent notice with each copy of the work that the
Library is used in it and that the Library and its use are covered by
this License.  You must supply a copy of this License.  If the work
during execution displays copyright notices, you must include the
copyright notice for the Library among them, as well as a reference
directing the user to the copy of this License.  Also, you must do one
of these things:

    a) Accompany the work with the complete corresponding
    machine-readable source code for the Library including whatever
    changes were used in the work (which must be distributed under
    Sections 1 and 2 above); and, if the work is an executable linked
    with the Library, with the complete machine-readable "work that
    uses the Library", as object code and/or source code, so that the
    user can modify the Library and then relink to produce a modified
    executable containing the modified Library.  (It is understood
    that the user who changes the contents of definitions files in the
    Library will not necessarily be able to recompile the application
    to use the modified definitions.)

    b) Use a suitable shared library mechanism for linking with the
    Library.  A suitable mechanism is one that (1) uses at run time a
    copy of the library already present on the user's computer system,
    rather than copying library functions into the executable, and (2)
    will operate properly with a modified version of the library, if
    the user installs one, as long as the modified version is
    interface-compatible with the version that the work was made with.

    c) Accompany the work with a written offer, valid for at
    least three years, to give the same user the materials
    specified in Subsection 6a, above, for a charge no more
    than the cost of performing this distribution.

    d) If distribution of the work is made by offering access to copy
    from a designated place, offer equivalent access to copy the above
    specified materials from the same place.

    e) Verify that the user has already received a copy of these
    materials or that you have already sent this user a copy.

  For an executable, the required form of the "work that uses the
Library" must include any data and utility programs needed for
reproducing the executable from it.  However, as a special exception,
the materials to be distributed need not include anything that is
normally distributed (in either source or binary form) with the major
components (compiler, kernel, and so on) of the operating system on
which the executable runs, unless that component itself accompanies
the executable.

  It may happen that this requirement contradicts the license
restrictions of other proprietary libraries that do not normally
accompany the operating system.  Such a contradiction means you cannot
use both them and the Library together in an executable that you
distribute.

  7. You may place library facilities that are a work based on the
Library side-by-side in a single library together with other library
facilities not covered by this License, and distribute such a combined
library, provided that the separate distribution of the work based on
the Library and of the other library facilities is otherwise
permitted, and provided that you do these two things:

    a) Accompany the combined library with a copy of the same work
    based on the Library, uncombined with any other library
    facilities.  This must be distributed under the terms of the
    Sections above.

    b) Give prominent notice with the combined library of the fact
    that part of it is a work based on the Library, and explaining
    where to find the accompanying uncombined form of the same work.

  8. You may not copy, modify, sublicense, link with, or distribute
the Library except as expressly provided under this License.  Any
attempt otherwise to copy, modify, sublicense, link with, or
distribute the Library is void, and will automatically terminate your
rights under this License.  However, parties who have received copies,
or rights, from you under this License will not have their licenses
terminated so long as such parties remain in full compliance.

  9. You are not required to accept this License, since you have not
signed it.  However, nothing else grants you permission to modify or
distribute the Library or its derivative works.  These actions are
prohibited by law if you do not accept this License.  Therefore, by
modifying or distributing the Library (or any work based on the
Library), you indicate your acceptance of this License to do so, and
all its terms and conditions for copying, distributing or modifying
the Library or works based on it.

  10. Each time you redistribute the Library (or any work based on the
Library), the recipient automatically receives a license from the
original licensor to copy, distribute, link with or modify the Library
subject to these terms and conditions.  You may not impose any further
restrictions on the recipients' exercise of the rights granted herein.
You are not responsible for enforcing compliance by third parties with
this License.

  11. If, as a consequence of a court judgment or allegation of patent
infringement or for any other reason (not limited to patent issues),
conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot
distribute so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you
may not distribute the Library at all.  For example, if a patent
license would not permit royalty-free redistribution of the Library by
all those who receive copies directly or indirectly through you, then
the only way you could satisfy both it and this License would be to
refrain entirely from distribution of the Library.

If any portion of this section is held invalid or unenforceable under any
particular circumstance, the balance of the section is intended to apply,
and the section as a whole is intended to apply in other circumstances.

It is not the purpose of this section to induce you to infringe any
patents or other property right claims or to contest validity of any
such claims; this section has the sole purpose of protecting the
integrity of the free software distribution system which is
implemented by public license practices.  Many people have made
generous contributions to the wide range of software distributed
through that system in reliance on consistent application of that
system; it is up to the author/donor to decide if he or she is willing
to distribute software through any other system and a licensee cannot
impose that choice.

This section is intended to make thoroughly clear what is believed to
be a consequence of the rest of this License.

  12. If the distribution and/or use of the Library is restricted in
certain countries either by patents or by copyrighted interfaces, the
original copyright holder who places the Library under this License may add
an explicit geographical distribution limitation excluding those countries,
so that distribution is permitted only in or among countries not thus
excluded.  In such case, this License incorporates the limitation as if
written in the body of this License.

  13. The Free Software Foundation may publish revised and/or new
versions of the Lesser General Public License from time to time.
Such new versions will be similar in spirit to the present version,
but may differ in detail to address new problems or concerns.

Each version is given a distinguishing version number.  If the Library
specifies a version number of this License which applies to it and
"any later version", you have the option of following the terms and
conditions either of that version or of any later version published by
the Free Software Foundation.  If the Library does not specify a
license version number, you may choose any version ever published by
the Free Software Foundation.

  14. If you wish to incorporate parts of the Library into other free
programs whose distribution conditions are incompatible with these,
write to the author to ask for permission.  For software which is
copyrighted by the Free Software Foundation, write to the Free
Software Foundation; we sometimes make exceptions for this.  Our
decision will be guided by the two goals of preserving the free status
of all derivatives of our free software and of promoting the sharing
and reuse of software generally.

                            NO WARRANTY

  15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO
WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW.
EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR
OTHER PARTIES PROVIDE THE LIBRARY "AS IS" WITHOUT WARRANTY OF ANY
KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE
LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME
THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN
WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY
AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU
FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR
CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE
LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING
RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A
FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF
SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
DAMAGES.

                     END OF TERMS AND CONDITIONS

           How to Apply These Terms to Your New Libraries

  If you develop a new library, and you want it to be of the greatest
possible use to the public, we recommend making it free software that
everyone can redistribute and change.  You can do so by permitting
redistribution under these terms (or, alternatively, under the terms of the
ordinary General Public License).

  To apply these terms, attach the following notices to the library.  It is
safest to attach them to the start of each source file to most effectively
convey the exclusion of warranty; and each file should have at least the
"copyright" line and a pointer to where the full notice is found.

    &lt;one line to give the library's name and a brief idea of what it does.&gt;
    Copyright (C) &lt;year&gt;  &lt;name of author&gt;

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

Also add information on how to contact you by electronic and paper mail.

You should also get your employer (if you work as a programmer) or your
school, if any, to sign a "copyright disclaimer" for the library, if
necessary.  Here is a sample; alter the names:

  Yoyodyne, Inc., hereby disclaims all copyright interest in the
  library `Frob' (a library for tweaking knobs) written by James Random Hacker.

  &lt;signature of Ty Coon&gt;, 1 April 1990
  Ty Coon, President of Vice

That's all there is to it!</programlisting>

        <para>See <olink>http://www.gnu.org/licenses/lgpl-2.1.html</olink> for
        more information.</para>
      </section>

      <section>
        <title>LPGL v3</title>

        <subtitle>GNU Lesser General Public License, version 3</subtitle>

        <para>The SDK incorporates technologies licensed under LPGL v3.</para>

        <programlisting>                   GNU LESSER GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt;
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.


  This version of the GNU Lesser General Public License incorporates
the terms and conditions of version 3 of the GNU General Public
License, supplemented by the additional permissions listed below.

  0. Additional Definitions.

  As used herein, "this License" refers to version 3 of the GNU Lesser
General Public License, and the "GNU GPL" refers to version 3 of the GNU
General Public License.

  "The Library" refers to a covered work governed by this License,
other than an Application or a Combined Work as defined below.

  An "Application" is any work that makes use of an interface provided
by the Library, but which is not otherwise based on the Library.
Defining a subclass of a class defined by the Library is deemed a mode
of using an interface provided by the Library.

  A "Combined Work" is a work produced by combining or linking an
Application with the Library.  The particular version of the Library
with which the Combined Work was made is also called the "Linked
Version".

  The "Minimal Corresponding Source" for a Combined Work means the
Corresponding Source for the Combined Work, excluding any source code
for portions of the Combined Work that, considered in isolation, are
based on the Application, and not on the Linked Version.

  The "Corresponding Application Code" for a Combined Work means the
object code and/or source code for the Application, including any data
and utility programs needed for reproducing the Combined Work from the
Application, but excluding the System Libraries of the Combined Work.

  1. Exception to Section 3 of the GNU GPL.

  You may convey a covered work under sections 3 and 4 of this License
without being bound by section 3 of the GNU GPL.

  2. Conveying Modified Versions.

  If you modify a copy of the Library, and, in your modifications, a
facility refers to a function or data to be supplied by an Application
that uses the facility (other than as an argument passed when the
facility is invoked), then you may convey a copy of the modified
version:

   a) under this License, provided that you make a good faith effort to
   ensure that, in the event an Application does not supply the
   function or data, the facility still operates, and performs
   whatever part of its purpose remains meaningful, or

   b) under the GNU GPL, with none of the additional permissions of
   this License applicable to that copy.

  3. Object Code Incorporating Material from Library Header Files.

  The object code form of an Application may incorporate material from
a header file that is part of the Library.  You may convey such object
code under terms of your choice, provided that, if the incorporated
material is not limited to numerical parameters, data structure
layouts and accessors, or small macros, inline functions and templates
(ten or fewer lines in length), you do both of the following:

   a) Give prominent notice with each copy of the object code that the
   Library is used in it and that the Library and its use are
   covered by this License.

   b) Accompany the object code with a copy of the GNU GPL and this license
   document.

  4. Combined Works.

  You may convey a Combined Work under terms of your choice that,
taken together, effectively do not restrict modification of the
portions of the Library contained in the Combined Work and reverse
engineering for debugging such modifications, if you also do each of
the following:

   a) Give prominent notice with each copy of the Combined Work that
   the Library is used in it and that the Library and its use are
   covered by this License.

   b) Accompany the Combined Work with a copy of the GNU GPL and this license
   document.

   c) For a Combined Work that displays copyright notices during
   execution, include the copyright notice for the Library among
   these notices, as well as a reference directing the user to the
   copies of the GNU GPL and this license document.

   d) Do one of the following:

       0) Convey the Minimal Corresponding Source under the terms of this
       License, and the Corresponding Application Code in a form
       suitable for, and under terms that permit, the user to
       recombine or relink the Application with a modified version of
       the Linked Version to produce a modified Combined Work, in the
       manner specified by section 6 of the GNU GPL for conveying
       Corresponding Source.

       1) Use a suitable shared library mechanism for linking with the
       Library.  A suitable mechanism is one that (a) uses at run time
       a copy of the Library already present on the user's computer
       system, and (b) will operate properly with a modified version
       of the Library that is interface-compatible with the Linked
       Version.

   e) Provide Installation Information, but only if you would otherwise
   be required to provide such information under section 6 of the
   GNU GPL, and only to the extent that such information is
   necessary to install and execute a modified version of the
   Combined Work produced by recombining or relinking the
   Application with a modified version of the Linked Version. (If
   you use option 4d0, the Installation Information must accompany
   the Minimal Corresponding Source and Corresponding Application
   Code. If you use option 4d1, you must provide the Installation
   Information in the manner specified by section 6 of the GNU GPL
   for conveying Corresponding Source.)

  5. Combined Libraries.

  You may place library facilities that are a work based on the
Library side by side in a single library together with other library
facilities that are not Applications and are not covered by this
License, and convey such a combined library under terms of your
choice, if you do both of the following:

   a) Accompany the combined library with a copy of the same work based
   on the Library, uncombined with any other library facilities,
   conveyed under the terms of this License.

   b) Give prominent notice with the combined library that part of it
   is a work based on the Library, and explaining where to find the
   accompanying uncombined form of the same work.

  6. Revised Versions of the GNU Lesser General Public License.

  The Free Software Foundation may publish revised and/or new versions
of the GNU Lesser General Public License from time to time. Such new
versions will be similar in spirit to the present version, but may
differ in detail to address new problems or concerns.

  Each version is given a distinguishing version number. If the
Library as you received it specifies that a certain numbered version
of the GNU Lesser General Public License "or any later version"
applies to it, you have the option of following the terms and
conditions either of that published version or of any later version
published by the Free Software Foundation. If the Library as you
received it does not specify a version number of the GNU Lesser
General Public License, you may choose any version of the GNU Lesser
General Public License ever published by the Free Software Foundation.

  If the Library as you received it specifies that a proxy can decide
whether future versions of the GNU Lesser General Public License shall
apply, that proxy's public statement of acceptance of any version is
permanent authorization for you to choose that version for the
Library.</programlisting>

        <para>See <olink>http://www.gnu.org/licenses/lgpl.html</olink> for
        more information.</para>
      </section>

      <section>
        <title>BSD License</title>

        <para>The SDK incorporates technology and data from the Intel OpenCV
        project which is licensed under the BSD License.</para>

        <programlisting>                       Intel License Agreement 
               For Open Source Computer Vision Library 

Copyright (C) 2000-2006, Intel Corporation, all rights reserved.
Third party copyrights are property of their respective owners. 

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

  * Redistribution's of source code must retain the above copyright notice,
    this list of conditions and the following disclaimer.

  * Redistribution's in binary form must reproduce the above copyright notice,
    this list of conditions and the following disclaimer in the documentation
    and/or other materials provided with the distribution.

  * The name of Intel Corporation may not be used to endorse or promote products
    derived from this software without specific prior written permission.

This software is provided by the copyright holders and contributors "as is" and
any express or implied warranties, including, but not limited to, the implied
warranties of merchantability and fitness for a particular purpose are disclaimed.
In no event shall the Intel Corporation or contributors be liable for any direct,
indirect, incidental, special, exemplary, or consequential damages
(including, but not limited to, procurement of substitute goods or services;
loss of use, data, or profits; or business interruption) however caused
and on any theory of liability, whether in contract, strict liability,
or tort (including negligence or otherwise) arising in any way out of
the use of this software, even if advised of the possibility of such damage.</programlisting>

        <para>See <olink>http://creativecommons.org/licenses/BSD/</olink> for
        more information.</para>
      </section>
    </section>
  </appendix>

  <appendix>
    <title>Tech Notes</title>

    <section>
      <title>Tools</title>

      <para>These are some of the tools we have found helpful in implementing
      the INDIface SDK.</para>

      <section>
        <title>Process Monitor</title>

        <para>ProcMon by Sysinternals (a subsidiary of Microsoft) has proven
        valuable to monitoring the reading/writing of files and registry
        entries as an application interacts with IfSearch. Start at <olink
        targetptr="http://technet.microsoft.com/en-us/sysinternals/bb896645.aspx">http://technet.microsoft.com/en-us/sysinternals/bb896645.aspx</olink>
        to download it.</para>
      </section>

      <section>
        <title>Network Monitor</title>

        <para>WireShark has proven useful when connecting new IP cameras. Get
        it at <olink
        targetptr="http://ww.wireshark.org">http://www.wireshark.org</olink>.</para>
      </section>

      <section>
        <title>Image Viewing and Manipulation</title>

        <para>IrfanView is a very helpful utility for viewing, manipulating,
        and converting still images and directories of images. Visit <olink
        targetptr="http://www.irfanview.com/">http://www.irfanview.com/</olink>
        if you are interested. Unfortunately it is only available on Windows
        at the moment.</para>
      </section>

      <section>
        <title>Screen Capture</title>

        <para>If you don't already have a favorite Print Screen utility, check
        out Gadwin PrintScreen. We have found the free version very capable,
        but the Professional version has more power. Visit them at <olink
        targetptr="http://www.gadwin.com/download/">http://www.gadwin.com/download/</olink>
        to see their products.</para>
      </section>

      <section>
        <title>Video File Manipulation</title>

        <para>AVS4YOU (r) has an excellent suite of multimedia and other
        applications. Start by downloading their Video Converter at
        <olink>http://www.avs4you.com/</olink> and see the note on exporting
        to a directory of PNGs at
        <olink>http://onlinehelp.avs4you.com/AVS-Video-Converter/Features/Editing/exportimage.aspx</olink>.</para>

        <informalfigure>
          <para></para>
        </informalfigure>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/ExportImagesWindow.png"></imagedata>
          </imageobject>
        </mediaobject>
      </section>
    </section>

    <section xml:id="secTechNote2">
      <title>How a Frame Becomes a Match</title>

      <subtitle>Sung to the tune of "How a Bill Becomes a Law"</subtitle>

      <para>This note describes in sequence how the INDIface SDK1 control
      parameters are applied at each step.</para>

      <para>The first figure shows how faces are detected from input frames
      and what criteria are used to qualify them for casual matching against
      INDIbase enrollments.</para>

      <figure>
        <title>Match Flow</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/SDK1-MatchBlocks.svg"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The second figure shows how a face earns "RedBox"
      distinction.</para>

      <figure>
        <title>"RedBox" Match</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/SDK1-RedBoxMatch.svg"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The third figure shows how a face can succeed at the Height
      Estimation, Skin Color, and Clothes Color analytics.</para>

      <figure>
        <title>Face-based Analytics</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="art/SDK1-Analytics.svg"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section xml:id="secMultipleInstances">
      <title>Multiple Instances</title>

      <para>Since the v1.60 release of the SDK, you have the ability to have
      multiple instances of the SDK running.</para>

      <para>Keep the following guidelines in mind:</para>

      <orderedlist>
        <listitem>
          <para>You can now specify the base registry key on the command line
          as <command>%[orgName/]appName</command>. The default is
          <filename>HKCU/Software/EclipseIR/IfSearch</filename>. Only one
          instance of <filename>IfSearch.exe</filename> should be running on a
          given registry base key at a time. If an instance of IfSearch is
          started while another is running, the running instance will
          terminate itself. There is a possibility that two instances could be
          started almost simultaneously and not know the other exists, so you
          should guard against this.</para>
        </listitem>

        <listitem>
          <para>Multiple instances can use different or share enrollment
          FaceBases. If multiple instances are sharing a FaceBase,</para>

          <itemizedlist>
            <listitem>
              <para>If multiple instances will be enrolling, they should have
              non-overlapping ranges of PersonKey and FaceKey. [External
              specification of key ranges isn't supported yet, but can be if
              needed.]</para>
            </listitem>

            <listitem>
              <para>Enrollment from one instance will not be visible in other
              instances until they are restarted. [This restriction can be
              eliminated if it becomes a problem before we switch to SQL-based
              enrollment.]</para>
            </listitem>
          </itemizedlist>
        </listitem>

        <listitem>
          <para>The data files and paths are now relative to the application's
          directory, so W:\hatever\INDIface\bin can be added to the system
          PATH and IfSearch.exe can be executed from any current directory
          now.</para>
        </listitem>
      </orderedlist>
    </section>
  </appendix>
</book>
